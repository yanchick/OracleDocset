<!DOCTYPE html><html lang="en-US"><head>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1"/>
<meta charset="utf-8"/>
<meta http-equiv="Content-Type" content="UTF-8"/>
<a class="dashingAutolink" name="autolink-5571"></a><a class="dashAnchor" name="//apple_ref/cpp/Package/Oracle%20Data%20Mining%20Basics"></a><title>Oracle Data Mining Basics</title>
<meta name="generator" content="DITA Open Toolkit version 1.8.5 (Mode = doc)"/>
<meta name="description" content="Understand the basic concepts of Oracle Data Mining."/>
<meta name="keywords" content="descriptive models, scoring, unsupervised models, anomaly detection, feature extraction, Automatic Data Preparation, sparse data, transparency"/>
<meta name="dcterms.created" content="2017-05-15T23:08:00Z"/>
<meta name="robots" content="all"/>
<meta name="dcterms.title" content="Data Mining Concepts"/>
<meta name="dcterms.identifier" content="E17692-19"/>
<meta name="dcterms.isVersionOf" content="DMCON"/>
<meta name="dcterms.rights" content="Copyright&nbsp;&copy;&nbsp;2005, 2017, Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved."/>
<link rel="Start" href="../index.htm" title="Home" type="text/html"/>
<link rel="Copyright" href="../dcommon/html/cpyr.htm" title="Copyright" type="text/html"/>

<script type="application/javascript" src="../dcommon/js/headfoot.js"></script>
<script type="application/javascript" src="../nav/js/doccd.js" charset="UTF-8"></script>
<link rel="Contents" href="toc.htm" title="Contents" type="text/html"/>
<link rel="Index" href="index.htm" title="Index" type="text/html"/>
<link rel="Prev" href="GUID-0B1D8B18-218B-46C6-92A1-2A499F961D49.htm" title="Previous" type="text/html"/>
<link rel="Next" href="GUID-3BC8FD92-9B6A-4612-A458-7E5FFDDC5EA7.htm" title="Next" type="text/html"/>
<link rel="alternate" href="E17692-19.pdf" title="PDF version" type="application/pdf"/>
<link rel="schema.dcterms" href="http://purl.org/dc/terms/"/>
<link rel="stylesheet" href="../dcommon/css/fusiondoc.css"/>
<link rel="stylesheet" type="text/css" href="../dcommon/css/header.css"/>
<link rel="stylesheet" type="text/css" href="../dcommon/css/footer.css"/>
<link rel="stylesheet" type="text/css" href="../dcommon/css/fonts.css"/>
<link rel="stylesheet" href="../dcommon/css/foundation.css"/>
<link rel="stylesheet" href="../dcommon/css/codemirror.css"/>
<link rel="stylesheet" type="text/css" title="Default" href="../nav/css/html5.css"/>
<link rel="stylesheet" href="../dcommon/css/respond-480-tablet.css"/>
<link rel="stylesheet" href="../dcommon/css/respond-768-laptop.css"/>
<link rel="stylesheet" href="../dcommon/css/respond-1140-deskop.css"/>
<script type="application/javascript" src="../dcommon/js/modernizr.js"></script>
<script type="application/javascript" src="../dcommon/js/codemirror.js"></script>
<script type="application/javascript" src="../dcommon/js/jquery.js"></script>
<script type="application/javascript" src="../dcommon/js/foundation.min.js"></script>
<script type="text/javascript" src="/s7.addthis.com/js/300/addthis_widget.js#pubid=ra-552992c80ef99c8d" async="async"></script>
<script type="application/javascript" src="../dcommon/js/jqfns.js"></script>
<script type="application/javascript" src="../dcommon/js/ohc-inline-videos.js"></script>
<!-- Add fancyBox -->
<link rel="stylesheet" href="../dcommon/fancybox/jquery.fancybox.css?v=2.1.5" type="text/css" media="screen"/>
<script type="text/javascript" src="../dcommon/fancybox/jquery.fancybox.pack.js?v=2.1.5"></script>
<!-- Optionally add helpers - button, thumbnail and/or media -->
<link rel="stylesheet" href="../dcommon/fancybox/helpers/jquery.fancybox-buttons.css?v=1.0.5" type="text/css" media="screen"/>
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-buttons.js?v=1.0.5"></script>
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-media.js?v=1.0.6"></script>
<link rel="stylesheet" href="../dcommon/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7" type="text/css" media="screen"/>
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-thumbs.js?v=1.0.7"></script>
</head>
<body>
<a href="#BEGIN" class="accessibility-top skipto" tabindex="0">Go to main content</a><header><!--
<div class="zz-skip-header"><a id="top" href="#BEGIN">Go to main content</a>--></header>
<div class="row" id="CONTENT">
<div class="IND large-9 medium-8 columns" dir="ltr">
<a id="BEGIN" name="BEGIN"></a>
<a id="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6"></a> <span id="PAGE" style="display:none;">8/29</span> <!-- End Header -->
<a id="DMCON620"></a>
<h1 id="DMCON-GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6" class="sect1"><span class="enumeration_chapter">3</span> Oracle Data Mining Basics</h1>
<div>
<p>Understand the basic concepts of Oracle Data Mining.</p>
<p><a id="d4810e19" class="indexterm-anchor"></a></p>
<ul style="list-style-type: disc;">
<li>
<p><a href="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6.htm#GUID-2E33469E-D6D2-4B31-B62D-3C2E2F88340B">Mining Functions</a></p>
</li>
<li>
<p><a href="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6.htm#GUID-BFA7FAAE-F5CB-4A42-886A-47B6D502B492">Algorithms</a></p>
</li>
<li>
<p><a href="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6.htm#GUID-1F28AA79-0508-40C4-BB62-A7A7EAFE5E2F">Data Preparation</a></p>
</li>
<li>
<p><a href="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6.htm#GUID-21677973-2248-4119-A560-24D7F2FD7EAD">In-Database Scoring</a></p>
</li>
</ul>
</div>
<a id="DMCON030"></a>
<div class="props_rev_3"><a id="GUID-2E33469E-D6D2-4B31-B62D-3C2E2F88340B"></a>
<h2 id="DMCON-GUID-2E33469E-D6D2-4B31-B62D-3C2E2F88340B" class="sect2">Mining Functions</h2>
<div>
<p>A basic understanding of data <a id="d4810e64" class="indexterm-anchor"></a>mining functions and algorithms is required for using Oracle Data Mining. This section introduces the concept of data mining functions. Algorithms are introduced in <span class="q">&#34;<a href="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6.htm#GUID-BFA7FAAE-F5CB-4A42-886A-47B6D502B492">Algorithms</a>&#34;</span>.</p>
<p>Each data mining <strong class="term">function</strong> specifies a class of problems that can be modeled and solved. Data mining functions fall generally into two categories: <strong class="term">supervised</strong> and <strong class="term">unsupervised</strong>. Notions of supervised and unsupervised learning are derived from the science of <a id="d4810e83" class="indexterm-anchor"></a>machine learning, which has been called a sub-area of <a id="d4810e86" class="indexterm-anchor"></a>artificial intelligence.</p>
<p>Artificial intelligence refers to the implementation and study of systems that exhibit autonomous intelligence or behavior of their own. Machine learning deals with techniques that enable devices to learn from their own performance and modify their own functioning. Data mining applies machine learning concepts to data.</p>
</div>
<a id="DMCON128"></a>
<div class="props_rev_3"><a id="GUID-2BB02332-4824-4D04-BE04-4265C75BEAA9"></a>
<h3 id="DMCON-GUID-2BB02332-4824-4D04-BE04-4265C75BEAA9" class="sect3">Supervised Data Mining</h3>
<div>
<p>Supervised <a id="d4810e111" class="indexterm-anchor"></a>learning is also known as <a id="d4810e114" class="indexterm-anchor"></a>directed learning. The learning process is directed by a previously known dependent attribute or <a id="d4810e117" class="indexterm-anchor"></a>target. Directed data mining attempts to explain the behavior of the target as a function of a set of independent attributes or predictors.</p>
<p>Supervised learning generally results in <a id="d4810e122" class="indexterm-anchor"></a>predictive models. This is in contrast to unsupervised learning where the goal is pattern detection.</p>
<p>The building of a supervised model involves <strong class="term">training</strong>, a process whereby the software analyzes many cases where the target value is already known. In the training process, the model &#34;learns&#34; the logic for making the prediction. For example, a model that seeks to identify the customers who are likely to respond to a promotion must be trained by analyzing the characteristics of many customers who are known to have responded or not responded to a promotion in the past.</p>
</div>
<a id="DMCON129"></a>
<div class="props_rev_3"><a id="GUID-ED7D5FD4-E421-44DC-A790-A96274E649B2"></a>
<h4 id="DMCON-GUID-ED7D5FD4-E421-44DC-A790-A96274E649B2" class="sect4">Supervised Learning: Testing</h4>
<div>
<p>Separate data sets are required for building (training) <a id="d4810e150" class="indexterm-anchor"></a>and testing some predictive models. The build data (training data) and test data must have the same column structure. Typically, one large table or view is split into two data sets: one for building the model, and the other for testing the model.</p>
<p>The process of applying the model to test data helps to determine whether the model, built on one chosen sample, is generalizable to other data. In particular, it helps to avoid the phenomenon of <a id="d4810e157" class="indexterm-anchor"></a>overfitting, which can occur when the logic of the model fits the build data too well and therefore has little predictive power.</p>
</div>
</div>
<a id="DMCON624"></a><a id="DMCON130"></a>
<div class="props_rev_3"><a id="GUID-99532F63-0417-45DC-908D-C5D7FCD083D9"></a>
<h4 id="DMCON-GUID-99532F63-0417-45DC-908D-C5D7FCD083D9" class="sect4">Supervised Learning: Scoring</h4>
<div>
<p><a id="d4810e180" class="indexterm-anchor"></a>Apply data, also <a id="d4810e185" class="indexterm-anchor"></a>called scoring data, is the actual <a id="d4810e190" class="indexterm-anchor"></a>population to which a model is applied. For example, you might build a model that identifies the characteristics of customers who frequently buy a certain product. To obtain a list of customers who shop at a certain store and are likely to buy a related product, you might apply the model to the customer data for that store. In this case, the store customer data is the scoring data.</p>
<p>Most supervised learning can be applied to a population of interest. The principal supervised mining techniques, <strong class="term">Classification</strong> and <strong class="term">Regression</strong>, can both be used for scoring.</p>
<p>Oracle Data Mining does not support the scoring operation for <strong class="term">Attribute Importance</strong>, another supervised function. Models of this type are built on a population of interest to obtain information about that population; they cannot be applied to separate data. An attribute importance model returns and ranks the attributes that are most important in predicting a target value.</p>
<p>Oracle Data Mining supports the supervised data mining functions described in<a id="d4810e210" class="indexterm-anchor"></a> the following table:</p>
<div class="tblformalwide" id="GUID-99532F63-0417-45DC-908D-C5D7FCD083D9__CIHDADDJ">
<p class="titleintable">Table 3-1 Oracle Data Mining Supervised Functions</p>
<table class="cellalignment4126" title="Oracle Data Mining Supervised Functions " summary="This table describes the predictive mining functions.">
<thead>
<tr class="cellalignment4117">
<th class="cellalignment4127" id="d4810e224">Function</th>
<th class="cellalignment4128" id="d4810e227">Description</th>
<th class="cellalignment4129" id="d4810e230">Sample Problem</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment4117">
<td class="cellalignment4130" id="d4810e235" headers="d4810e224">
<p>Attribute Importance<a id="d4810e238" class="indexterm-anchor"></a></p>
</td>
<td class="cellalignment4131" headers="d4810e235 d4810e227">
<p>Identifies the attributes that are most important in predicting a target attribute</p>
</td>
<td class="cellalignment4132" headers="d4810e235 d4810e230">
<p>Given customer response to an affinity card program, find the most significant predictors</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4130" id="d4810e247" headers="d4810e224">
<p><a id="d4810e249" class="indexterm-anchor"></a><a id="d4810e251" class="indexterm-anchor"></a>Classification</p>
</td>
<td class="cellalignment4131" headers="d4810e247 d4810e227">
<p>Assigns items to discrete classes and predicts the class to which an item belongs</p>
</td>
<td class="cellalignment4132" headers="d4810e247 d4810e230">
<p>Given demographic data about a set of customers, predict customer response to an affinity card program</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4130" id="d4810e263" headers="d4810e224">
<p><a id="d4810e265" class="indexterm-anchor"></a><a id="d4810e267" class="indexterm-anchor"></a>Regression</p>
</td>
<td class="cellalignment4131" headers="d4810e263 d4810e227">
<p>Approximates and forecasts continuous values</p>
</td>
<td class="cellalignment4132" headers="d4810e263 d4810e230">
<p>Given demographic and purchasing data about a set of customers, predict customers&#39; age</p>
</td>
</tr>
</tbody>
</table>
</div>
<!-- class="inftblhruleinformal" --></div>
</div>
</div>
<a id="DMCON131"></a>
<div class="props_rev_3"><a id="GUID-91F9B08B-B262-4726-A109-A90E68A062D0"></a>
<h3 id="DMCON-GUID-91F9B08B-B262-4726-A109-A90E68A062D0" class="sect3">Unsupervised Data Mining</h3>
<div>
<p>Unsupervised <a id="d4810e302" class="indexterm-anchor"></a>learning is non-directed. There is no distinction between dependent and independent attributes. There is no previously-known result to guide the algorithm in building the model.</p>
<p>Unsupervised learning can be used for <strong class="term">descriptive</strong> purposes. It can also be used to make predictions.</p>
</div>
<a id="DMCON135"></a><a id="DMCON132"></a>
<div class="props_rev_3"><a id="GUID-039F01D5-C94A-4571-9C08-3B9D8AB78629"></a>
<h4 id="DMCON-GUID-039F01D5-C94A-4571-9C08-3B9D8AB78629" class="sect4">Unsupervised Learning: Scoring</h4>
<div>
<p>Although unsupervised data mining does not <a id="d4810e341" class="indexterm-anchor"></a>specify a <a id="d4810e346" class="indexterm-anchor"></a>target, most unsupervised learning can be applied to a population of interest. For exa<a id="d4810e349" class="indexterm-anchor"></a>mple, <a id="d4810e354" class="indexterm-anchor"></a>clustering models use descriptive data mining techniques, but they can be applied to classify cases according to their cluster assignments. <a id="d4810e357" class="indexterm-anchor"></a><a id="d4810e359" class="indexterm-anchor"></a><strong class="term">Anomaly detection</strong>, <a id="d4810e367" class="indexterm-anchor"></a>although unsupervised, is typically used to predict whether a data point is typical among a set of cases.</p>
<p>Oracle Data Mining supports the scoring operation for <a id="d4810e374" class="indexterm-anchor"></a><a id="d4810e376" class="indexterm-anchor"></a><strong class="term">Clustering</strong> and <strong class="term">Feature Extraction</strong>, both unsupervised mining functions. Oracle Data Mining does not support the <a id="d4810e384" class="indexterm-anchor"></a>scoring operation for <a id="d4810e387" class="indexterm-anchor"></a><strong class="term">Association Rules</strong>, another unsupervised function. Association models are built on a population of interest to obtain information about that population; they cannot be applied to separate data. An association model returns rules that explain how items or events are associated with each other. The association rules are returned with statistics that can be used to rank them according to their probability.</p>
<p>Oracle Data Mining supports the unsupervised functions described in the following table:</p>
<div class="tblformalwide" id="GUID-039F01D5-C94A-4571-9C08-3B9D8AB78629__CHDDDCEE">
<p class="titleintable">Table 3-2 Oracle Data Mining Unsupervised Functions</p>
<table class="cellalignment4126" title="Oracle Data Mining Unsupervised Functions" summary="This table describes the descriptive data mining functions.">
<thead>
<tr class="cellalignment4117">
<th class="cellalignment4133" id="d4810e405">Function</th>
<th class="cellalignment4134" id="d4810e408">Description</th>
<th class="cellalignment4135" id="d4810e411">Sample Problem</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e416" headers="d4810e405">
<p><a id="d4810e418" class="indexterm-anchor"></a><a id="d4810e420" class="indexterm-anchor"></a>Anomaly Detection</p>
</td>
<td class="cellalignment4137" headers="d4810e416 d4810e408">
<p>Identifies items (outliers) that do not satisfy the characteristics of &#34;normal&#34; data</p>
</td>
<td class="cellalignment4138" headers="d4810e416 d4810e411">
<p>Given demographic data about a set of customers, identify customer purchasing behavior that is significantly different from the norm</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e432" headers="d4810e405">
<p>Association<a id="d4810e435" class="indexterm-anchor"></a><a id="d4810e437" class="indexterm-anchor"></a> Rules</p>
</td>
<td class="cellalignment4137" headers="d4810e432 d4810e408">
<p>Finds items that tend to co-occur in the data and specifies the rules that govern their co-occurrence</p>
</td>
<td class="cellalignment4138" headers="d4810e432 d4810e411">
<p>Find the items that tend to be purchased together and specify their relationship</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e449" headers="d4810e405">
<p>Clustering<a id="d4810e452" class="indexterm-anchor"></a><a id="d4810e454" class="indexterm-anchor"></a></p>
</td>
<td class="cellalignment4137" headers="d4810e449 d4810e408">
<p>Finds natural groupings in the data</p>
</td>
<td class="cellalignment4138" headers="d4810e449 d4810e411">
<p>Segment demographic data into clusters and rank the probability that an individual belongs to a given cluster</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e465" headers="d4810e405">
<p>Feature Extraction<a id="d4810e468" class="indexterm-anchor"></a><a id="d4810e470" class="indexterm-anchor"></a></p>
</td>
<td class="cellalignment4137" headers="d4810e465 d4810e408">
<p>Creates new <a id="d4810e477" class="indexterm-anchor"></a>attributes (features) using linear combinations of the original attributes</p>
</td>
<td class="cellalignment4138" headers="d4810e465 d4810e411">
<p>Given demographic data about a set of customers, group the attributes into general characteristics of the customers</p>
</td>
</tr>
</tbody>
</table>
</div>
<!-- class="inftblhruleinformal" -->
<div class="infoboxnotealso" id="GUID-039F01D5-C94A-4571-9C08-3B9D8AB78629__GUID-9E85C738-D8A7-4312-B0ED-FE99ED243465">
<p class="notep1">See Also:</p>
<ul style="list-style-type: disc;">
<li>
<p><span class="q">&#34; <a href="GUID-3BC8FD92-9B6A-4612-A458-7E5FFDDC5EA7.htm">Mining Functions</a>&#34;</span> for details about the mining functions supported by Oracle Data Mining</p>
</li>
<li>
<p><span class="q">&#34;<a href="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6.htm#GUID-21677973-2248-4119-A560-24D7F2FD7EAD">In-Database Scoring</a>&#34;</span> for more information about scoring</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<a id="DMCON031"></a>
<div class="props_rev_3"><a id="GUID-BFA7FAAE-F5CB-4A42-886A-47B6D502B492"></a>
<h2 id="DMCON-GUID-BFA7FAAE-F5CB-4A42-886A-47B6D502B492" class="sect2">Algorithms</h2>
<div>
<p>An <a id="d4810e520" class="indexterm-anchor"></a>algorithm is a mathematical procedure for solving a specific kind of problem. Oracle Data Mining supports at least one algorithm for each data mining function. For some functions, you can choose among several algorithms. For example, Oracle Data Mining supports four classification algorithms.</p>
<p>Each data mining model is produced by a specific algorithm. Some data mining problems can best be solved by using more than one algorithm. This necessitates the development of more than one model. For example, you might first use a feature extraction model to create an optimized set of predictors, then a classification model to make a prediction on the results.</p>
</div>
<a id="DMCON137"></a><a id="DMCON136"></a>
<div class="props_rev_3"><a id="GUID-208DD1B9-4B6E-4D51-A1C2-C58356DECE4E"></a>
<h3 id="DMCON-GUID-208DD1B9-4B6E-4D51-A1C2-C58356DECE4E" class="sect3">Oracle Data Mining Supervised Algorithms</h3>
<div>
<p>Oracle <a id="d4810e548" class="indexterm-anchor"></a>Data Mining supports the supervised data mining <a id="d4810e553" class="indexterm-anchor"></a>algorithms described in the following table. The algorithm abbreviations are used throughout this manual.</p>
<div class="tblformalwide" id="GUID-208DD1B9-4B6E-4D51-A1C2-C58356DECE4E__BHCGGHBA">
<p class="titleintable">Table 3-3 Oracle Data Mining Algorithms for Supervised Functions</p>
<table class="cellalignment4126" title="Oracle Data Mining Algorithms for Supervised Functions" summary="Oracle Algorithms for Supervised Data Mining">
<thead>
<tr class="cellalignment4117">
<th class="cellalignment4133" id="d4810e569">Algorithm</th>
<th class="cellalignment4139" id="d4810e572">Function</th>
<th class="cellalignment4140" id="d4810e575">Description</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e580" headers="d4810e569">
<p><a id="d4810e582" class="indexterm-anchor"></a><a id="d4810e584" class="indexterm-anchor"></a>Decision Tree</p>
</td>
<td class="cellalignment4141" headers="d4810e580 d4810e572">
<p><a id="d4810e591" class="indexterm-anchor"></a><a id="d4810e593" class="indexterm-anchor"></a>Classification</p>
</td>
<td class="cellalignment4142" headers="d4810e580 d4810e575">
<p>Decision trees extract predictive information in the form of human-understandable rules. The rules are if-then-else expressions; they explain the decisions that lead to the prediction.</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e602" headers="d4810e569">
<p><a id="d4810e604" class="indexterm-anchor"></a><a id="d4810e606" class="indexterm-anchor"></a>Generalized Linear Models</p>
</td>
<td class="cellalignment4141" headers="d4810e602 d4810e572">
<p>Classification and <a id="d4810e614" class="indexterm-anchor"></a><a id="d4810e616" class="indexterm-anchor"></a>Regression</p>
</td>
<td class="cellalignment4142" headers="d4810e602 d4810e575">
<p>Generalized Linear Models (GLM) implement <a id="d4810e624" class="indexterm-anchor"></a>logistic regression for classification of binary targets and<a id="d4810e627" class="indexterm-anchor"></a> linear regression for continuous targets. GLM classification supports<a id="d4810e630" class="indexterm-anchor"></a> confidence bounds for prediction probabilities. GLM regression supports confidence bounds for predictions.</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e634" headers="d4810e569">
<p><a id="d4810e636" class="indexterm-anchor"></a><a id="d4810e638" class="indexterm-anchor"></a>Minimum Description Length</p>
</td>
<td class="cellalignment4141" headers="d4810e634 d4810e572">
<p><a id="d4810e645" class="indexterm-anchor"></a><a id="d4810e647" class="indexterm-anchor"></a>Attribute Importance</p>
</td>
<td class="cellalignment4142" headers="d4810e634 d4810e575">
<p>Minimum Description Length (MDL) is an information theoretic model selection principle. MDL assumes that the simplest, most compact representation of data is the best and most probable explanation of the data.</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e656" headers="d4810e569">
<p><a id="d4810e658" class="indexterm-anchor"></a><a id="d4810e660" class="indexterm-anchor"></a>Naive Bayes</p>
</td>
<td class="cellalignment4141" headers="d4810e656 d4810e572">
<p>Classification</p>
</td>
<td class="cellalignment4142" headers="d4810e656 d4810e575">
<p>Naive Bayes makes predictions using Bayes&#39; Theorem, which derives the probability of a prediction from the underlying evidence, as observed in the data.</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e672" headers="d4810e569">
<p><a id="d4810e674" class="indexterm-anchor"></a><a id="d4810e676" class="indexterm-anchor"></a>Support Vector Machines</p>
</td>
<td class="cellalignment4141" headers="d4810e672 d4810e572">
<p>Classification and Regression</p>
</td>
<td class="cellalignment4142" headers="d4810e672 d4810e575">
<p>Distinct versions of Support Vector Machines (SVM) use different kernel functions to handle different types of data sets. <a id="d4810e687" class="indexterm-anchor"></a><a id="d4810e691" class="indexterm-anchor"></a>Linear and Gaussian (nonlinear) kernels are supported.</p>
<p>SVM <a id="d4810e698" class="indexterm-anchor"></a>classification attempts to separate the target classes with the widest possible margin.</p>
<p>SVM <a id="d4810e705" class="indexterm-anchor"></a>regression tries to find a continuous function such that the maximum number of data points lie within an epsilon-wide tube around it.</p>
</td>
</tr>
</tbody>
</table>
</div>
<!-- class="inftblhruleinformal" --></div>
</div>
<a id="DMCON139"></a><a id="DMCON138"></a>
<div class="props_rev_3"><a id="GUID-B232C37E-6B54-43C7-8498-1B9D63219A09"></a>
<h3 id="DMCON-GUID-B232C37E-6B54-43C7-8498-1B9D63219A09" class="sect3">Oracle Data Mining Unsupervised Algorithms</h3>
<div>
<p>Oracle Data Mining <a id="d4810e731" class="indexterm-anchor"></a>supports the unsupervised data mining algorithms described in the following table. The algorithm abbreviations are used throughout this manual.</p>
<div class="tblformalwide" id="GUID-B232C37E-6B54-43C7-8498-1B9D63219A09__BHCHAHIG">
<p class="titleintable">Table 3-4 Oracle Data Mining Algorithms for Unsupervised Functions</p>
<table class="cellalignment4126" title="Oracle Data Mining Algorithms for Unsupervised Functions" summary="Lists the unsupervised data mining algorithms supported by Oracle Data Mining.">
<thead>
<tr class="cellalignment4117">
<th class="cellalignment4133" id="d4810e747">Algorithm</th>
<th class="cellalignment4143" id="d4810e750">Function</th>
<th class="cellalignment4144" id="d4810e753">Description</th>
</tr>
</thead>
<tbody>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e758" headers="d4810e747">
<p><a id="d4810e760" class="indexterm-anchor"></a><a id="d4810e762" class="indexterm-anchor"></a>Apriori</p>
</td>
<td class="cellalignment4145" headers="d4810e758 d4810e750">
<p><a id="d4810e769" class="indexterm-anchor"></a><a id="d4810e771" class="indexterm-anchor"></a>Association</p>
</td>
<td class="cellalignment4146" headers="d4810e758 d4810e753">
<p>Apriori performs market basket analysis by identifying co-occurring items (frequent itemsets) within a set. Apriori finds rules with support greater than a specified minimum <a id="d4810e779" class="indexterm-anchor"></a>support and <a id="d4810e784" class="indexterm-anchor"></a>confidence greater than a specified minimum confidence.</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e790" headers="d4810e747">
<p><a id="d4810e792" class="indexterm-anchor"></a><a id="d4810e794" class="indexterm-anchor"></a>Expectation Maximization</p>
</td>
<td class="cellalignment4145" headers="d4810e790 d4810e750">
<p>Clustering</p>
</td>
<td class="cellalignment4146" headers="d4810e790 d4810e753">
<p>Expectation Maximization (EM) is a density estimation algorithm that performs probabilistic clustering. In density estimation, the goal is to construct a density function that captures how a given population is distributed. The density estimate is based on observed data that represents a sample of the population.</p>
<p>Oracle Data Mining supports probabilistic clustering and data frequency estimates and other applications of Expectation Maximization.</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e808" headers="d4810e747">
<p><a id="d4810e810" class="indexterm-anchor"></a><a id="d4810e812" class="indexterm-anchor"></a><span class="italic">k</span>-Means</p>
</td>
<td class="cellalignment4145" headers="d4810e808 d4810e750">
<p><a id="d4810e823" class="indexterm-anchor"></a><a id="d4810e825" class="indexterm-anchor"></a>Clustering</p>
</td>
<td class="cellalignment4146" headers="d4810e808 d4810e753">
<p><span class="italic">k</span>-Means is a distance-based clustering algorithm that partitions the data into a predetermined number of clusters. Each cluster has a centroid (center of gravity). Cases (individuals within the population) that are in a cluster are close to the centroid.</p>
<p>Oracle Data Mining supports an enhanced version of <span class="italic">k</span>-Means. It goes beyond the classical implementation by defining <a id="d4810e840" class="indexterm-anchor"></a><a id="d4810e842" class="indexterm-anchor"></a>a hierarchical parent-child relationship of clusters.</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e848" headers="d4810e747">
<p><a id="d4810e850" class="indexterm-anchor"></a><a id="d4810e852" class="indexterm-anchor"></a>Non-Negative Matrix Factorization</p>
</td>
<td class="cellalignment4145" headers="d4810e848 d4810e750">
<p><a id="d4810e859" class="indexterm-anchor"></a><a id="d4810e861" class="indexterm-anchor"></a>Feature Extraction</p>
</td>
<td class="cellalignment4146" headers="d4810e848 d4810e753">
<p>Non-Negative Matrix Factorization (NMF) generates new attributes using linear combinations of the original attributes. The <a id="d4810e869" class="indexterm-anchor"></a>coefficients of the linear combinations are non-negative. During model apply, an NMF model maps the original data into the new set of attributes (features) discovered by the model.</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e875" headers="d4810e747">
<p><a id="d4810e877" class="indexterm-anchor"></a>One Class Support Vector Machines<a id="d4810e882" class="indexterm-anchor"></a></p>
</td>
<td class="cellalignment4145" headers="d4810e875 d4810e750">
<p><a id="d4810e886" class="indexterm-anchor"></a><a id="d4810e888" class="indexterm-anchor"></a>Anomaly Detection</p>
</td>
<td class="cellalignment4146" headers="d4810e875 d4810e753">
<p>One-class<a id="d4810e896" class="indexterm-anchor"></a> SVM builds a profile of one class. When the model is applied, it identifies cases that are somehow different from that profile. This allows for the detection of rare cases that are not necessarily related to each other.</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e902" headers="d4810e747">
<p>Orthogonal Partitioning Clustering<a id="d4810e905" class="indexterm-anchor"></a><a id="d4810e907" class="indexterm-anchor"></a></p>
</td>
<td class="cellalignment4145" headers="d4810e902 d4810e750">
<p>Clustering</p>
</td>
<td class="cellalignment4146" headers="d4810e902 d4810e753">
<p>Orthogonal Partitioning Clustering (o-cluster) creates a hierarchical, grid-based clustering model. The algorithm creates clusters that define dense areas in the attribute space. A sensitivity parameter defines the baseline density level.</p>
</td>
</tr>
<tr class="cellalignment4117">
<td class="cellalignment4136" id="d4810e918" headers="d4810e747">
<p><a id="d4810e920" class="indexterm-anchor"></a>Singular Value Decomposition and <a id="d4810e925" class="indexterm-anchor"></a><a id="d4810e927" class="indexterm-anchor"></a>Principal Component Analysis</p>
</td>
<td class="cellalignment4145" headers="d4810e918 d4810e750">
<p>Feature Extraction</p>
</td>
<td class="cellalignment4146" headers="d4810e918 d4810e753">
<p>Singular Value Decomposition (SVD) and Principal Component Analysis (PCA) are orthogonal linear transformations that are optimal at capturing the underlying variance of the data. This property is extremely useful for reducing the dimensionality of high-dimensional data and for supporting meaningful data visualization.</p>
<p>In addition to dimensionality reduction, SVD and PCA have a number of other important applications, such as data de-noising (smoothing), data compression, matrix inversion, and solving a system of linear equations.</p>
</td>
</tr>
</tbody>
</table>
</div>
<!-- class="inftblhruleinformal" -->
<div class="infoboxnotealso" id="GUID-B232C37E-6B54-43C7-8498-1B9D63219A09__GUID-A11E89AE-F8F1-4423-B1BE-208C43F29836">
<p class="notep1">See Also:</p>
<p><span class="q">&#34; <a href="GUID-B901A29B-218C-4F37-91E0-AA94631364E3.htm" title="Part III provides basic conceptual information about the algorithms supported by Oracle Data Mining. There is at least one algorithm for each of the mining functions.">Algorithms</a>&#34;</span> for details about the algorithms supported by Oracle Data Mining</p>
</div>
</div>
</div>
</div>
<a id="DMCON625"></a>
<div class="props_rev_3"><a id="GUID-1F28AA79-0508-40C4-BB62-A7A7EAFE5E2F"></a>
<h2 id="DMCON-GUID-1F28AA79-0508-40C4-BB62-A7A7EAFE5E2F" class="sect2">Data Preparation</h2>
<div>
<p>The quality of a model depends to a large extent on the quality of the data used to build (train) it. Much of the time spent in any given data mining project is devoted to data preparation. The data must be carefully inspected, cleansed, and transformed, and algorithm-appropriate data preparation methods must be applied.</p>
<p>The process of data preparation is further complicated by the fact that any data to which a model is applied, whether for testing or for scoring, must undergo the same transformations as the data used to train the model.</p>
</div>
<a id="DMCON626"></a>
<div class="props_rev_3"><a id="GUID-C0EF2463-8975-4B15-9AC2-B64EE5C14324"></a>
<h3 id="DMCON-GUID-C0EF2463-8975-4B15-9AC2-B64EE5C14324" class="sect3">Oracle Data Mining Simplifies Data Preparation</h3>
<div>
<p>Oracle Data Mining offers several features that significantly simplify the process of data preparation:</p>
<ul style="list-style-type: disc;">
<li>
<p>Embedded data preparation: <a id="d4810e1004" class="indexterm-anchor"></a>The transformations used in training the model are embedded in the model and automatically executed whenever the model is applied to new data. If you specify transformations for the model, you only have to specify them once.</p>
</li>
<li>
<p>Automatic Data Preparation (ADP): Oracle Data Mining supports an automated data preparation mode. When ADP is active, Oracle Data Mining automatically performs the data transformations required by the algorithm. The transformation instructions are embedded in the model along with any user-specified transformation instructions.</p>
</li>
<li>
<p>Automatic management of missing values and sparse data: <a id="d4810e1013" class="indexterm-anchor"></a> Oracle Data Mining uses consistent methodology across mining algorithms to handle sparsity and missing values.</p>
</li>
<li>
<p>Transparency: Oracle Data Mining provides model details, which are a view of the attributes that are internal to the model. This insight into the inner details of the model is possible because of reverse transformations, which map the transformed attribute values to a form that can be interpreted by a user. Where possible, attribute values are reversed to the original column values. Reverse transformations are also applied to the target of a supervised model, thus the results of scoring are in the same units as the units of the original target.</p>
</li>
<li>
<p>Tools for custom data preparation: Oracle Data Mining provides many common transformation routines in the <code class="codeph">DBMS_DATA_MINING_TRANSFORM</code> PL/SQL package. You can use these routines, or develop your own routines in SQL, or both. The SQL language is well suited for implementing transformations in the database. You can use custom transformation instructions along with ADP or instead of ADP.</p>
</li>
</ul>
</div>
</div>
<a id="DMCON627"></a>
<div class="props_rev_3"><a id="GUID-FD2B3D12-42CA-4F35-AD2D-BAFD8BBE918A"></a>
<h3 id="DMCON-GUID-FD2B3D12-42CA-4F35-AD2D-BAFD8BBE918A" class="sect3">Case Data</h3>
<div>
<p>Most data mining algorithms act on single-record case data, where the information for each case is stored in a separate row. The data attributes for the cases are stored in the columns.</p>
<p>When the data is organized in transactions, the data for one case (one transaction) is stored in many rows. An example of transactional data is market basket data. With the single exception of Association Rules, which can operate on native transactional data, Oracle Data Mining algorithms require single-record case organization.</p>
</div>
<a id="DMCON628"></a>
<div class="props_rev_3"><a id="GUID-BF8E80CD-60C1-4127-95F7-C39AD83B8E63"></a>
<h4 id="DMCON-GUID-BF8E80CD-60C1-4127-95F7-C39AD83B8E63" class="sect4">Nested Data</h4>
<div>
<p>Oracle Data Mining supports attributes in nested columns. A transactional table can be cast as a nested column and included in a table of single-record case data. Similarly, star schemas can be cast as nested columns. With nested data transformations, Oracle Data Mining can effectively mine data originating from multiple sources and configurations.</p>
</div>
</div>
</div>
<a id="DMCON638"></a>
<div class="props_rev_3"><a id="GUID-32CBE82E-326F-4BCF-B45D-26E3F1660191"></a>
<h3 id="DMCON-GUID-32CBE82E-326F-4BCF-B45D-26E3F1660191" class="sect3">Text Data</h3>
<div>
<p><a id="d4810e1087" class="indexterm-anchor"></a><a id="d4810e1089" class="indexterm-anchor"></a>Oracle Data Mining interprets <code class="codeph">CLOB</code> columns and long <code class="codeph">VARCHAR2</code> columns automatically as unstructured text. Additionally, you can specify columns of short <code class="codeph">VARCHAR2</code>, <code class="codeph">CHAR</code>, <code class="codeph">BLOB</code>, and <code class="codeph">BFILE</code> as unstructured text. Unstructured text includes data items such as web pages, document libraries, Power Point presentations, product specifications, emails, comment fields in reports, and call center notes.</p>
<p>Oracle Data Mining uses Oracle Text utilities and term weighting strategies to transform unstructured text for mining. In text transformation, text terms are extracted and given numeric values in a text index. The text transformation process is configurable for the model and for individual attributes. Once transformed, the text can by mined with a data mining algorithm.</p>
<div class="infoboxnotealso" id="GUID-32CBE82E-326F-4BCF-B45D-26E3F1660191__GUID-6C03D17B-52E9-4073-94A4-7CE6EC0B4600">
<p class="notep1">See Also:</p>
<ul style="list-style-type: disc;">
<li>
<p><span class="q">&#34;Preparing the Data&#34;</span> in <a class="olink DMPRG005" target="_blank" href="../DMPRG/GUID-E1AB599C-1921-4BD7-B06B-FC466180A460.htm#DMPRG005"><span><cite>Oracle Data Mining User&rsquo;s Guide</cite></span></a></p>
</li>
<li>
<p><span class="q">&#34;Transforming the Data&#34;</span> in <a class="olink DMPRG578" target="_blank" href="../DMPRG/GUID-C3FDDEC7-8CC9-4AC1-A6C3-75D91E26B703.htm#DMPRG578"><span><cite>Oracle Data Mining User&rsquo;s Guide</cite></span></a></p>
</li>
<li>
<p><span class="q">&#34;Mining Unstructured Text&#34;</span> in <a class="olink DMPRG602" target="_blank" href="../DMPRG/GUID-DC9371F7-B16A-43C7-A563-5C2016064E72.htm#DMPRG602"><span><cite>Oracle Data Mining User&rsquo;s Guide</cite></span></a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<a id="DMCON630"></a>
<div class="props_rev_3"><a id="GUID-21677973-2248-4119-A560-24D7F2FD7EAD"></a>
<h2 id="DMCON-GUID-21677973-2248-4119-A560-24D7F2FD7EAD" class="sect2">In-Database Scoring</h2>
<div>
<p>Scoring is the application of a data mining algorithm to new data. In traditional data mining, models are built using specialized software on a remote system and deployed to another system for scoring. This is a cumbersome, error-prone process open to security violations and difficulties in data synchronization.</p>
<p>With Oracle Data Mining, scoring is easy and secure. The scoring engine and the data both reside within the database. Scoring is an extension to the SQL language, so the results of mining can easily be incorporated into applications and reporting systems.</p>
</div>
<a id="DMCON668"></a>
<div class="props_rev_3"><a id="GUID-6BFCB980-D04A-42B6-A3BD-74FCF352A500"></a>
<h3 id="DMCON-GUID-6BFCB980-D04A-42B6-A3BD-74FCF352A500" class="sect3">Parallel Execution and Ease of Administration</h3>
<div>
<p>In-database <a id="d4810e1187" class="indexterm-anchor"></a>scoring provides performance advantages. All Oracle Data Mining scoring routines support <a id="d4810e1192" class="indexterm-anchor"></a>parallel execution, which significantly reduces the time required for executing complex queries and scoring large data sets. For information about parallel execution, refer to <a class="olink VLDBG010" target="_blank" href="../VLDBG/GUID-3E2AE088-2505-465E-A8B2-AC38813EA355.htm#VLDBG010"><span class="italic">Oracle Database VLDB and Partitioning Guide</span>.</a></p>
<p>In-database mining minimizes the IT effort needed to support data mining initiatives. Using standard database techniques, models can easily be refreshed (re-created) on more recent data and redeployed. The deployment is immediate since the scoring query remains the same; only the underlying model is replaced in the database.</p>
</div>
</div>
<a id="DMCON631"></a><a id="DMCON632"></a><a id="DMCON669"></a>
<div class="props_rev_3"><a id="GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49"></a>
<h3 id="DMCON-GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49" class="sect3">SQL Functions for Model Apply and Dynamic Scoring</h3>
<div>
<p>In Oracle Data Mining, <a id="d4810e1224" class="indexterm-anchor"></a>scoring is performed by SQL language functions. The functions perform prediction, clustering, and feature extraction. The functions can be invoked in two different ways: By applying a mining model object (<a href="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6.htm#GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABDDAEF">Example 3-1</a>), or by executing an analytic clause that computes the mining analysis dynamically and applies it to the data (<a href="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6.htm#GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABGEAJA">Example 3-2</a>). Dynamic scoring, which eliminates the need for a model, can supplement, or even replace, the more traditional data mining methodology described in <span class="q">&#34;The Data Mining Process&#34;</span>.</p>
<p>In <a href="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6.htm#GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABDDAEF">Example 3-1</a>, the <code class="codeph">PREDICTION_PROBABILITY</code> function applies the model svmc_sh_clas_sample, created in <a href="GUID-0B1D8B18-218B-46C6-92A1-2A499F961D49.htm#GUID-EC7AC64D-CFB7-48CE-9B54-9E553DD79234__BABEHGJB">Example 2-1</a>, to score the data in <code class="codeph">mining_data_apply_v</code>. The function returns the ten customers in Italy who are most likely to use an affinity card.</p>
<p>In <a href="GUID-2116E665-721E-4EBA-AFE1-A30D6E8078C6.htm#GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABGEAJA">Example 3-2</a>, the functions <code class="codeph">PREDICTION</code> and <code class="codeph">PREDICTION_PROBABILITY</code> use the analytic syntax (the <code class="codeph">OVER</code> () clause) to dynamically score the data in <code class="codeph">mining_data_apply_v</code>. The query returns the customers who currently do not have an affinity card with the probability that they are likely to use.</p>
<div class="example" id="GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABDDAEF">
<p class="titleinexample">Example 3-1 Applying a Mining Model to Score Data</p>
<pre dir="ltr">SELECT cust_id FROM
  (SELECT cust_id, 
        rank() over (order by PREDICTION_PROBABILITY(svmc_sh_clas_sample, 1
                     USING *) DESC, cust_id) rnk
   FROM mining_data_apply_v
   WHERE country_name = &#39;Italy&#39;)
WHERE rnk &lt;= 10
ORDER BY rnk;

   CUST_ID
----------
    101445
    100179
    100662
    100733
    100554
    100081
    100344
    100324
    100185
    101345
</pre></div>
<!-- class="example" -->
<div class="example" id="GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__BABGEAJA">
<p class="titleinexample">Example 3-2 Executing an Analytic Function to Score Data</p>
<pre dir="ltr">SELECT cust_id, pred_prob FROM
  (SELECT cust_id, affinity_card, 
    PREDICTION(FOR TO_CHAR(affinity_card) USING *) OVER () pred_card,
    PREDICTION_PROBABILITY(FOR TO_CHAR(affinity_card),1 USING *) OVER () pred_prob
   FROM mining_data_build_v)
WHERE affinity_card = 0
AND pred_card = 1
ORDER BY pred_prob DESC;

   CUST_ID PRED_PROB
---------- ---------
    102434       .96
    102365       .96
    102330       .96
    101733       .95
    102615       .94
    102686       .94
    102749       .93
    .
    .
    .
    101656       .51
</pre></div>
<!-- class="example" -->
<div class="section">
<div class="infoboxnotealso" id="GUID-B4916CE4-F771-4111-A5DF-20977FB3EE49__GUID-8093957F-12DC-4983-BCFC-0A172439956C">
<p class="notep1">See Also:</p>
<ul style="list-style-type: disc;">
<li>
<p><span class="q">&#34;<a href="GUID-8232ABAD-E6B9-4C70-B227-E00738040932.htm#GUID-DD4AF6C3-485F-4B0F-87E5-BBEADCFCB8DA">The Data Mining Process</a>&#34;</span></p>
</li>
<li>
<p>&#34;Data Mining Functions&#34; in <a class="olink SQLRF20030" target="_blank" href="../SQLRF/functions002.htm#SQLRF20030"><span><cite>Oracle Database SQL Language Reference</cite></span></a></p>
</li>
<li>
<p>Chapter 6, &#34;Scoring and Deployment&#34; in <a class="olink DMPRG004" target="_blank" href="../DMPRG/GUID-891F460B-CB68-43F6-AD21-D7C9FD1CF670.htm#DMPRG004"><span><cite>Oracle Data Mining User&rsquo;s Guide</cite></span></a></p>
</li>
</ul>
</div>
</div>
<!-- class="section" --></div>
</div>
</div>
</div>
<!-- class="ind" --><!-- Start Footer -->
</div>
<!-- add extra wrapper close div-->
<footer><!--
<hr />
<table class="cellalignment4116">
<tr>
<td class="cellalignment4123">
<table class="cellalignment4121">
<tr>
<td class="cellalignment4120"><a href="GUID-0B1D8B18-218B-46C6-92A1-2A499F961D49.htm"><img width="24" height="24" src="../dcommon/gifs/leftnav.gif" alt="Go to previous page" /><br />
<span class="icon">Previous</span></a></td>
<td class="cellalignment4120"><a href="GUID-3BC8FD92-9B6A-4612-A458-7E5FFDDC5EA7.htm"><img width="24" height="24" src="../dcommon/gifs/rightnav.gif" alt="Go to next page" /><br />
<span class="icon">Next</span></a></td>
</tr>
</table>
</td>
<td class="cellalignment-copyrightlogo"><img width="144" height="18" src="../dcommon/gifs/oracle.gif" alt="Oracle" /><br />
Copyright&nbsp;&copy;&nbsp;2005, 2017, Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved.<br />
<a href="../dcommon/html/cpyr.htm">Legal Notices</a></td>
<td class="cellalignment4125">
<table class="cellalignment4119">
<tr>
<td class="cellalignment4120"><a href="../index.htm"><img width="24" height="24" src="../dcommon/gifs/doclib.gif" alt="Go to Documentation Home" /><br />
<span class="icon">Home</span></a></td>
<td class="cellalignment4120"><a href="../nav/portal_booklist.htm"><img width="24" height="24" src="../dcommon/gifs/booklist.gif" alt="Go to Book List" /><br />
<span class="icon">Book List</span></a></td>
<td class="cellalignment4120"><a href="toc.htm"><img width="24" height="24" src="../dcommon/gifs/toc.gif" alt="Go to Table of Contents" /><br />
<span class="icon">Contents</span></a></td>
<td class="cellalignment4120"><a href="index.htm"><img width="24" height="24" src="../dcommon/gifs/index.gif" alt="Go to Index" /><br />
<span class="icon">Index</span></a></td>
<td class="cellalignment4120"><a href="../nav/mindx.htm"><img width="24" height="24" src="../dcommon/gifs/masterix.gif" alt="Go to Master Index" /><br />
<span class="icon">Master Index</span></a></td>
<td class="cellalignment4120"><a href="../dcommon/html/feedback.htm"><img width="24" height="24" src="../dcommon/gifs/feedbck2.gif" alt="Go to Feedback page" /><br />
<span class="icon">Contact Us</span></a></td>
</tr>
</table>
</td>
</tr>
</table>
--></footer>
<noscript>
<p>Scripting on this page enhances content navigation, but does not change the content in any way.</p>
</noscript>


</body></html>