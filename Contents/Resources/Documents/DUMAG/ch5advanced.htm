<!DOCTYPE html><html lang="en"><head>
<meta http-equiv="X-UA-Compatible" content="IE=edge"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1"/>
<meta charset="utf-8"/>
<a class="dashingAutolink" name="autolink-5856"></a><a class="dashAnchor" name="//apple_ref/cpp/Package/Advanced%20Topics%20in%20the%20DMU"></a><title>Advanced Topics in the DMU</title>
<meta name="generator" content="Oracle DARB XHTML Converter (Mode = document) - Merged Version 1067"/>
<meta name="dcterms.created" content="2015-08-21T21:34:33Z"/>
<meta name="robots" content="all"/>
<meta name="dcterms.title" content="Database Migration Assistant for Unicode Guide"/>
<meta name="dcterms.identifier" content="E48475-07"/>
<meta name="dcterms.isVersionOf" content="DUMAG"/>
<meta name="dcterms.rights" content="Copyright&nbsp;&copy;&nbsp;2011, 2015,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved."/>
<link rel="Start" href="../index.htm" title="Home" type="text/html"/>
<link rel="Copyright" href="../dcommon/html/cpyr.htm" title="Copyright" type="text/html"/>

<script type="application/javascript" src="../dcommon/js/headfoot.js"></script>
<script type="application/javascript" src="../nav/js/doccd.js"></script>
<link rel="Contents" href="toc.htm" title="Contents" type="text/html"/>
<link rel="Index" href="index.htm" title="Index" type="text/html"/>
<link rel="Glossary" href="glossary.htm" title="Glossary" type="text/html"/>
<link rel="Prev" href="ch4scenarios.htm" title="Previous" type="text/html"/>
<link rel="Next" href="ch6cleansing.htm" title="Next" type="text/html"/>
<link rel="alternate" href="E48475-07.pdf" title="PDF version" type="application/pdf"/>
<link rel="schema.dcterms" href="http://purl.org/dc/terms/"/>
<link rel="stylesheet" href="../dcommon/css/fusiondoc.css"/>
<link rel="stylesheet" type="text/css" href="../dcommon/css/header.css"/>
<link rel="stylesheet" type="text/css" href="../dcommon/css/footer.css"/>
<link rel="stylesheet" type="text/css" href="../dcommon/css/fonts.css"/>
<link rel="stylesheet" href="../dcommon/css/foundation.css"/>
<link rel="stylesheet" href="../dcommon/css/codemirror.css"/>
<link rel="stylesheet" type="text/css" title="Default" href="../nav/css/html5.css"/>
<link rel="stylesheet" href="../dcommon/css/respond-480-tablet.css"/>
<link rel="stylesheet" href="../dcommon/css/respond-768-laptop.css"/>
<link rel="stylesheet" href="../dcommon/css/respond-1140-deskop.css"/>
<script type="application/javascript" src="../dcommon/js/modernizr.js"></script>
<script type="application/javascript" src="../dcommon/js/codemirror.js"></script>
<script type="application/javascript" src="../dcommon/js/jquery.js"></script>
<script type="application/javascript" src="../dcommon/js/foundation.min.js"></script>
<script type="text/javascript" src="/s7.addthis.com/js/300/addthis_widget.js#pubid=ra-552992c80ef99c8d" async="async"></script>
<script type="application/javascript" src="../dcommon/js/jqfns.js"></script>
<script type="application/javascript" src="../dcommon/js/ohc-inline-videos.js"></script>
<!-- Add fancyBox -->
<link rel="stylesheet" href="../dcommon/fancybox/jquery.fancybox.css?v=2.1.5" type="text/css" media="screen"/>
<script type="text/javascript" src="../dcommon/fancybox/jquery.fancybox.pack.js?v=2.1.5"></script>
<!-- Optionally add helpers - button, thumbnail and/or media -->
<link rel="stylesheet" href="../dcommon/fancybox/helpers/jquery.fancybox-buttons.css?v=1.0.5" type="text/css" media="screen"/>
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-buttons.js?v=1.0.5"></script>
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-media.js?v=1.0.6"></script>
<link rel="stylesheet" href="../dcommon/fancybox/helpers/jquery.fancybox-thumbs.css?v=1.0.7" type="text/css" media="screen"/>
<script type="text/javascript" src="../dcommon/fancybox/helpers/jquery.fancybox-thumbs.js?v=1.0.7"></script>
</head>
<body>
<a href="#BEGIN" class="accessibility-top skipto" tabindex="0">Go to main content</a><header><!--
<div class="zz-skip-header"><a id="top" href="#BEGIN">Go to main content</a>--></header>
<div class="row" id="CONTENT">
<div class="IND large-9 medium-8 columns" dir="ltr">
<a id="BEGIN" name="BEGIN"></a>
<span id="PAGE" style="display:none;">8/11</span> <!-- End Header -->
<div id="DUMAG347" class="chapter"><a id="CIHBDEBH"></a>
<h1 class="chapter"><span class="secnum">5</span> Advanced Topics in the DMU</h1>
<p>This chapter illustrates various advanced topics that you should consider when working with the Database Migration Assistant for Unicode. It includes:</p>
<ul>
<li>
<p><a href="#CIHHGBCA">Excluding Columns and Tables From Migration</a></p>
</li>
<li>
<p><a href="#CIHGEIHG">Handling Non-Accessible Data</a></p>
</li>
<li>
<p><a href="#CIHHBBII">Migrating Data Dictionary Contents</a></p>
</li>
<li>
<p><a href="#CIHDGGCE">Working with Multilingual Columns</a></p>
</li>
<li>
<p><a href="#CIHEJAIG">Advanced Convertibility Issues</a></p>
</li>
<li>
<p><a href="#CIHEIHIF">Adapting Applications for Unicode Migration</a></p>
</li>
<li>
<p><a href="#BABFJEGB">Repairing Database Character Set Metadata</a></p>
</li>
<li>
<p><a href="#BABJDDGJ">Updating the DMU Version</a></p>
</li>
<li>
<p><a href="#BABGHDHJ">DMU Accessibility Information</a></p>
</li>
</ul>
<a id="CIHHGBCA"></a>
<div id="DUMAG348" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">Excluding Columns and Tables From Migration</h2>
<p>In certain situ<a id="sthref169"></a><a id="sthref170"></a><a id="sthref171"></a>ations, you may want to exclude selected columns or tables from scanning or conversion steps of the migration process. Situations in which this may be justified are the following:</p>
<ul>
<li>
<p>You need to solve a problem of multiple character sets in a single column (see <a href="#CIHDGGCE">&#34;Working with Multilingual Columns&#34;</a>).</p>
</li>
<li>
<p>There is a character column in the database that contains binary data. You cannot migrate the column to a binary data type (<code dir="ltr">RAW</code>, <code dir="ltr">LONG</code> <code dir="ltr">RAW</code>, or <code dir="ltr">BLOB</code>), because you are unable to modify applications accessing the database, for example, because they are not developed in-house. You want to avoid converting the column so that the applications may continue to access the data in a pass-through configuration.</p>
</li>
<li>
<p>There is a very large table in the database, with terabytes of data, which &ndash; you are absolutely sure &ndash; contains no convertible data. Such tables:</p>
<ul>
<li>
<p>Cannot contain <code dir="ltr">CLOB</code> columns, unless the current database character set is multibyte.</p>
</li>
<li>
<p>Can contain only character columns with internal application codes, yes/no flags, credit card numbers or other data known to contain only basic ASCII characters.</p>
</li>
<li>
<p>Must not contain data entered by end users from keyboards that support non-ASCII characters even if the users are supposed to enter English text only. Standard keyboards of computers running Microsoft Windows always allow such characters to be entered.</p>
</li>
</ul>
<p>You may want to avoid scanning such a large table to reduce the scanning time of the whole database. Oracle strongly recommends that you scan even very large tables at least once.</p>
</li>
<li>
<p>As with the case of very large tables, you may want to avoid scanning archival data stored in read-only tablespaces on slow storage devices, such as DVD-ROM jukeboxes. Again, you should be absolutely sure that the tables contain no data requiring conversion.</p>
</li>
<li>
<p>There are read-only tablespaces or a read-only table that you cannot change to read/write for some important reason. You want to be able to convert the rest of the database to Unicode, even though the tablespace or the table contains convertible data that the DMU will not be able to convert. You accept that data in the tablespace or the table will be unreadable after the conversion unless appropriate workarounds are implemented or the DMU converts the data later in validation mode.</p>
</li>
<li>
<p>As with read-only tablespaces, if you have an offline tablespace or offline data file that you cannot switch back online, the DMU will not be able to scan or convert data in this tablespace or data file. You still want to convert the rest of the database and you accept that the contents of the tablespace or the data file may be unreadable if you later switch the tablespace or the data file back online. You can use the DMU in validation mode to later convert this data.</p>
</li>
</ul>
<p>See <a href="#CIHGEIHG">&#34;Handling Non-Accessible Data&#34;</a> for further discussion about database objects in read-only and offline mode.</p>
<p>To exclude a table from scanning, simply deselect it on the object selection page of the Scan Wizard.</p>
<p>To exclude a column from conversion, open its Column Properties tab (see <a href="ch3tasks.htm#BABHFFIJ">&#34;Viewing and Setting Column Properties&#34;</a>) and set the Exclude from Conversion property on the Converting subtab to Yes. The DMU does not consider columns excluded from conversion when checking for convertibility issues that prevent you from starting the conversion step. To exclude a table from conversion, exclude all its convertible columns.</p>
</div>
<!-- class="sect1" -->
<a id="CIHGEIHG"></a>
<div id="DUMAG349" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">Handling Non-Accessible Data</h2>
<p>Certain types of data in a database might be inaccessible to applications. The data may be non-updatable or it may be even unreadable. The DMU cannot convert non-updatable data and it can neither convert nor scan unreadable data. Data with access restrictions is data contained in any of the following database objects:</p>
<ul>
<li>
<p><a href="#CIHEACDC">Read-Only Tables Considerations</a></p>
</li>
<li>
<p><a href="#CIHBAFHF">Read-Only Tablespaces Considerations</a></p>
</li>
<li>
<p><a href="#CIHDICGH">Offline Tablespaces and Data Files Considerations</a></p>
</li>
<li>
<p><a href="#CIHGAABJ">Working With External Tables</a></p>
</li>
</ul>
<a id="CIHEACDC"></a>
<div id="DUMAG350" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Read-Only Tables Considerations</h3>
<p>All Oracle <a id="sthref172"></a><a id="sthref173"></a>Databases since release 11.1 support the read-only mode for database tables. Thus, users who want table contents to be protected against updates can alter a table to read-only mode. A read-only table can be queried, its constraints modified, its segment moved, shrunk, or expanded, but none of its column values can be modified in any way and no new rows can be added. Users can alter the table back to read/write mode and again to read-only, as many times as required.</p>
<p>Read-only tables cannot be updated and, thus, their contents could not be converted if required by the DMU. Therefore, the DMU automatically alters read-only tables to read/write mode before attempting conversion. After the conversion, the mode is changed back to read-only.</p>
<p>A read-only table may also be re-created, if it is converted using the &#34;Copy data using <code dir="ltr">CREATE</code> <code dir="ltr">TABLE</code> <code dir="ltr">AS</code> <code dir="ltr">SELECT</code>&#34; conversion method.</p>
</div>
<!-- class="sect2" -->
<a id="CIHBAFHF"></a>
<div id="DUMAG351" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Read-Only Tablespaces Considerations</h3>
<p>A tablespac<a id="sthref174"></a><a id="sthref175"></a>e can be put into read-only mode. This prevents any data stored in it from being updated. Data files of read-only tablespaces could be put on read-only media, such as DVD-ROM, and moved to jukeboxes, which are used as cheaper storage for seldom accessed archived data. The data files might also remain on standard read/write disk storage devices. For example, historical data in very large databases is frequently moved to read-only tablespaces. The tablespaces are backed up only once, just after putting them into read-only mode. As read-only tablespaces cannot change, no further backups are required. This significantly reduces backup time of the very large databases.</p>
<p>If any segment of a table, including partition, <code dir="ltr">CLOB</code>, <code dir="ltr">VARRAY</code>, and IOT overflow segments, contains data that requires conversion, and the segment belongs to a read-only tablespace, the DMU cannot successfully convert the table. The DMU reports this as a convertibility issue on the Migration Status tab and does not allow you to start the conversion step until the problem is resolved.</p>
<p>The approach to resolve this convertibility issue depends on the reason for which the problematic tablespaces have been put into read-only mode. If the reason was to reduce backup time, and the data is still on standard disk devices, put the tablespaces back into read/write mode, convert them with the rest of the database, put into read-only mode again and refresh the backup.</p>
<p>If the tablespaces have been put into read-only mode and moved to read-only media, the possible solutions are:</p>
<ul>
<li>
<p>If enough disk storage can be arranged for, permanently or temporarily, to accommodate all read-only tablespaces with convertible data, copy the tablespaces to this storage, make them read/write, convert together with the rest of the database, make read-only again, and either leave on the disk storage, or put back on read-only media. With large number of read-only tablespaces containing convertible data, this may not be a viable solution.</p>
</li>
<li>
<p>Create an auxiliary database in the same character set as the main database, that is, the database to be migrated. Move the read-only tablespaces logically to the new database using the transportable tablespace feature, leaving the data files physically in their current location. Create a database link in the main database pointing to the new database. By creating auxiliary views or through application changes, make the read-only data in the auxiliary database visible to applications connecting to the main database. The data will be converted while being transported over the database link.</p>
</li>
</ul>
</div>
<!-- class="sect2" -->
<a id="CIHDICGH"></a>
<div id="DUMAG352" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Offline Tablespaces and Data Files Considerations</h3>
<p>A tablespace or<a id="sthref176"></a><a id="sthref177"></a> selected data files in a tablespace may be put into offline mode. Any data contained in an offline tablespace or data file is inaccessible for both reading and writing. Offline mode is required by various administrative operations on data files, such as renaming or moving from one storage device to another.</p>
<p>If any segment of a table, including partition, <code dir="ltr">LOB</code>, <code dir="ltr">VARRAY</code>, and IOT overflow segments, contains character data that may require conversion, and the segment belongs to an offline tablespace or data file, the DMU can neither scan nor convert the table. You must put such a tablespace or data file back to online mode before scanning or converting the affected tables. Otherwise, errors, such as ORA-00376, will be reported in the scan and conversion steps.</p>
<p>The DMU will report an error on the Migration Status tab and prevent you from starting the conversion step if convertible data is found in an offline data file.</p>
</div>
<!-- class="sect2" -->
<a id="CIHGAABJ"></a>
<div id="DUMAG353" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Working With External Tables</h3>
<p>An external table is a table<a id="sthref178"></a><a id="sthref179"></a> whose data resides in files outside of the database. The database contains definitions of table columns (metadata) but table rows are fetched from external files when a query referencing the table is issued. Oracle Database supports two access drivers that read the external files: <code dir="ltr">ORACLE_LOADER</code> and <code dir="ltr">ORACLE_DATAPUMP</code>. <code dir="ltr">ORACLE_LOADER</code> reads text files that are in the format supported by the SQL*Loader. <code dir="ltr">ORACLE_DATAPUMP</code> supports binary files that are compatible with the Data Pump Export and Import utilities (<code dir="ltr">expdp</code> and <code dir="ltr">impdp</code>).</p>
<p>DML statements modifying external tables are not supported. An <code dir="ltr">ORACLE_DATAPUMP</code> external file may be created and filled with data when an external table is created with the statement <code dir="ltr">CREATE</code> <code dir="ltr">TABLE</code> <code dir="ltr">&hellip;</code> <code dir="ltr">ORGANIZATION</code> <code dir="ltr">EXTERNAL</code> <code dir="ltr">&hellip;</code> <code dir="ltr">AS</code> <code dir="ltr">SELECT</code> but it cannot be later modified from inside the database. <code dir="ltr">ORACLE_LOADER</code> files must be created and modified outside of the database. The DMU does not convert external files along with the database contents.</p>
<p>When an external table is created, the character set of its data files is established as follows:</p>
<ul>
<li>
<p>The character set of an <code dir="ltr">ORACLE_DATAPUMP</code> file is stored in the data file itself when the file is created by the <code dir="ltr">ORACLE_DATAPUMP</code> driver or the Data Pump Export utility.</p>
</li>
<li>
<p>The character set of an <code dir="ltr">ORACLE_LOADER</code> file may be specified in the <code dir="ltr">CHARACTERSET</code> parameter in the access parameters clause of the external table definition. If the parameter is not specified, the database character set is used to interpret the contents of the file.</p>
</li>
</ul>
<p>If the declared character set of an external file differs from the database character set, the database converts the data automatically while reading it. If the database character set changes but the character set of the external file does not change, the database adapts itself to the new configuration and converts external files to the new database character set.</p>
<div class="infobox-note">
<p class="notep1">Caution:</p>
If the character set of an <code dir="ltr">ORACLE_LOADER</code> file is not declared explicitly in the access parameters clause of an external table definition, a change to the database character set also changes the implicit declaration of the character set of the external file. If the file itself is not converted to the new database character set, the external file declaration no longer corresponds to the real character set of the file and the external table is no longer correctly readable.
<p>Before migrating a database to Unicode, you must either add missing explicit character set declarations to all external table definitions or convert the file contents to the new database character set.</p>
</div>
<div id="DUMAG354" class="sect3"><!-- infolevel="all" infotype="General" --><a id="sthref180"></a>
<h4 class="sect3">Cleansing External Tables</h4>
<p>Even though the DMU d<a id="sthref181"></a>oes not convert external tables, it does include them in the scanning step of the migration process. The scan results show you, if the file contents will still fit into the declared column lengths after migration, even if data expands in conversion to the new Unicode database character set. The results also warn you if any illegal character codes are present in the external files. These codes will no longer be readable if the file contents must be converted on the fly.</p>
<p>If the scan report shows invalid binary representation issues, you must identify the source of the invalid codes, as discussed in <a href="ch1overview.htm#CJAHJBDG">&#34;Invalid Binary Storage Representation of Data&#34;</a> and <a href="ch6cleansing.htm#BCGCHIBB">&#34;Cleansing Scenario 3: Cleansing Invalid Representation Issues&#34;</a>.</p>
<p>The following sections describe actions that you can perform to cleanse the external tables from various reported issues.</p>
</div>
<!-- class="sect3" -->
<div id="DUMAG355" class="sect3"><!-- infolevel="all" infotype="General" --><a id="sthref182"></a>
<h4 class="sect3">Cleansing Length Issues</h4>
<p>If the scan report <a id="sthref183"></a>shows length issues in external table contents, you can alter the table to lengthen the affected columns or migrate them to character semantics. The DMU does not support cleansing actions on external tables so you must do this in another tool, such as SQL*Plus or SQL Developer. Changing a <code dir="ltr">VARCHAR2</code> column to <code dir="ltr">CLOB</code> may be necessary, if the data expands above 4000 bytes. To change the column data type to <code dir="ltr">CLOB</code>, you must re-create the external table. This is a fast operation, as only metadata changes are involved, but you must remember to re-create any dependent objects, such as grants.</p>
</div>
<!-- class="sect3" -->
<div id="DUMAG356" class="sect3"><!-- infolevel="all" infotype="General" --><a id="sthref184"></a>
<h4 class="sect3">Correcting Character Set Declaration of ORACLE_LOADER Files</h4>
<p>If character values of an external table are read by the <code dir="ltr">ORACLE_LOADER</code> driver in a pass-through configuration, that is, the declared character set of data files and the database character set are the same, but the real character set of data contents is different, you can repair the configuration by declaring the real character set in the access parameters clause of the external table definition. You must not change the declaration in a production database before the database is converted, because this would break the pass-through configuration and make the table unreadable.</p>
<p>Before the database is converted, you should change the Assumed Column Character Set property of the affected external table columns &ndash; as described in <a href="ch6cleansing.htm#BCGGBIEJ">&#34;Setting the Assumed Character Set&#34;</a> &ndash; to the identified real character set of the data files and rescan the table to identify any additional length and invalid binary representation issues that might come up after the data file character set declaration is corrected.</p>
<p>Oracle recommends that you create a script to modify all affected access parameter clauses in the database and run it directly after the conversion phase of the DMU finishes successfully.</p>
</div>
<!-- class="sect3" -->
<div id="DUMAG357" class="sect3"><!-- infolevel="all" infotype="General" --><a id="sthref185"></a>
<h4 class="sect3">Correcting Character Set Declaration of ORACLE_DATAPUMP Files</h4>
<p>If character values of an external table are read by the <code dir="ltr">ORACLE_DATAPUMP</code> driver in a pass-through configuration, that is, in the character set configuration described in the previous section, you should ensure that the Data Pump input files are correctly re-tagged with their real character set directly after the database is converted to Unicode.</p>
<p>Unfortunately, the character set declaration is stored internally in Data Pump files and cannot be easily modified. A more complex procedure is needed to fix the declaration. Alternatively, you can arrange for the external table files to be provided in <code dir="ltr">ORACLE_LOADER</code> format, so that you have full control over their character set declaration in the external table&#39;s access parameters clause.</p>
<p>If a Data Pump file is used in a pass-through configuration, it means that its source (exported) database also works in this configuration, as otherwise it could not produce an incorrectly tagged file. The recommended approach to fix the character set declaration of a Data Pump file is, therefore, to fix the database character set of its source database.</p>
<p>If you have no control over the character set of the source database, you must:</p>
<ul>
<li>
<p>Create an auxiliary, empty database in the character set of the Data Pump files</p>
</li>
<li>
<p>Import the files &ndash; this will happen in the pass-through configuration</p>
</li>
<li>
<p>Change the database character set to the real character set of the files</p>
</li>
<li>
<p>Export the files and use them for the external table in the main database (after it is migrated to Unicode)</p>
</li>
</ul>
<p>Contact Oracle Support for information about fixing a pass-through configuration by changing the database character set with the Character Set Scanner utility (<code dir="ltr">csscan</code>) and the <code dir="ltr">csalter.plb</code> script.</p>
<p>The following PL/SQL code enables you to identify the character set of a Data Pump file:</p>
<pre dir="ltr">DECLARE
    et_directory_name VARCHAR2(30) := &#39;&lt;directory object name&gt;&#39;;
                                         -- for example, &#39;DATA_PUMP_DIR&#39;
    et_file_name       VARCHAR2(4000) := &#39;&lt;file name&gt;&#39;;
                                         -- for example, &#39;EXPDAT.DMP&#39;
    et_file_info       ku$_dumpfile_info;
    et_file_type       NUMBER;
BEGIN
   dbms_datapump.get_dumpfile_info
      ( filename =&gt; et_file_name
      , directory =&gt; et_directory_name
      , info_table =&gt; et_file_info
      , filetype =&gt; et_file_type );
   FOR i IN et_file_info.FIRST..et_file_info.LAST LOOP
      IF et_file_info.EXISTS(i) THEN
         IF et_file_info(i).item_code = 11 THEN
            dbms_output.put_line( &#39;Character set of the file is &#39; ||
                                       et_file_info(i).value );
         END IF;
      END IF;
   END LOOP;
END;
</pre></div>
<!-- class="sect3" -->
<div id="DUMAG358" class="sect3"><!-- infolevel="all" infotype="General" --><a id="sthref186"></a>
<h4 class="sect3">Fixing Corrupted Character Codes</h4>
<p>If analysis of <a id="sthref187"></a>invalid binary representation issues in an external table shows that there are only some corrupted character codes in some character values &ndash; usually due to a user error, an application defect, or a temporary configuration problem &ndash; the values should be corrected in the source database and the affected files re-exported or unloaded again.</p>
<p>With <code dir="ltr">ORACLE_LOADER</code> files, you can fix the invalid codes directly in the files with a text editor. However, the solution is effective only if the files are not regularly replaced with a new version produced from the same source database contents.</p>
</div>
<!-- class="sect3" -->
<div id="DUMAG359" class="sect3"><!-- infolevel="all" infotype="General" --><a id="sthref188"></a>
<h4 class="sect3">Handling Binary Data</h4>
<p>Invalid binary re<a id="sthref189"></a>presentation issues in an external table may also be caused by binary data being declared and fetched as character data by the external table driver. To cleanse this type of issues, you must redefine the external table to use binary data types, such as <code dir="ltr">RAW</code> and <code dir="ltr">BLOB</code>, for the affected columns.</p>
<p>Oracle strongly discourages attempts to continue using the pass-through configuration to fetch the binary data into a database with a multibyte character set, such as UTF8 or AL32UTF8. Such configuration may cause unexpected issues now or in the future.</p>
</div>
<!-- class="sect3" -->
<div id="DUMAG360" class="sect3"><!-- infolevel="all" infotype="General" --><a id="sthref190"></a>
<h4 class="sect3">Performance Considerations for ORACLE_LOADER Files</h4>
<p>The Oracle Database Utilities Guide l<a id="sthref191"></a>ists several performance hints for the <code dir="ltr">ORACLE_LOADER</code> driver. The following hints are especially relevant in the context of character set migration to Unicode:</p>
<ul>
<li>
<p>Single-byte character sets are the fastest to process.</p>
</li>
<li>
<p>Fixed-width character sets are faster to process than varying-width character sets.</p>
</li>
<li>
<p>Byte-length semantics for varying-width character sets are faster to process than character-length semantics.</p>
</li>
<li>
<p>Having the character set in the data file match the character set of the database is faster than a character set conversion.</p>
</li>
</ul>
<p>If you can choose between leaving an <code dir="ltr">ORACLE_LOADER</code> file in its current character set and arranging for the file to be provided in the new Unicode database character set, you should consider the following conclusions drawn from the above hints:</p>
<ul>
<li>
<p>If the current character set of the file is multibyte, using UTF8 or AL32UTF8 database character set for the file will not significantly influence the parsing time, that is, time needed to divide the file into records and fields, but it will save on conversion time. Performance of the queries referencing the external table will be better.</p>
</li>
<li>
<p>If the current character set of the file is single-byte, using UTF8 or AL32UTF8 database character set for the file will slow down parsing but it will save on conversion time. You should benchmark both configurations to find out which one is more efficient.</p>
</li>
<li>
<p>If you decide to convert the file from a single-byte character set to UTF8 or AL32UTF8, try to express field lengths and positions in bytes versus characters, if maximizing query performance is important.</p>
</li>
</ul>
</div>
<!-- class="sect3" --></div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="CIHHBBII"></a>
<div id="DUMAG361" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">Migrating Data Dictionary Contents</h2>
<p>The DMU classifies<a id="sthref192"></a> tables as belonging to the data dictionary based on the schema that owns them. Schemas that the DMU considers to be in the data dictionary are those displayed under the Data Dictionary node in the Navigator panel &ndash; see <a href="ch2migrasteps.htm#CHDCCIDD">&#34;Introduction to the DMU Interface and Navigation&#34;</a>. If you create your own table in a data dictionary schema, such as <code dir="ltr">SYS</code> or <code dir="ltr">SYSTEM</code>, the DMU will treat it as other data dictionary tables. Oracle discourages creating user tables in data dictionary schemas.In this release, the DMU supports character set conversion of only a subset of metadata kept in the data dictionary tables. Therefore, the DMU handles data dictionary tables differently from other tables in the database, as described in the following sections.</p>
<div id="DUMAG362" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref193"></a>
<h3 class="sect2">Scanning Data Dictionary Tables</h3>
<p>Most data dictionary tables are scanned in the same way as user-defined tables. The usual convertibility issues &ndash; data exceeding column limit, data exceeding data type limit, and data having invalid binary representation &ndash; are reported in the same way as well. The difference lies in reporting of data that needs conversion to the target Unicode character set. Because the DMU does not support converting of data dictionary contents in this release, except for a few exceptions, non-convertible columns containing data requiring conversion are marked with the yellow triangle warning icon and are considered a convertibility issue that prevents starting the database conversion step. The Database Scan Report filtering condition &#34;With Some Issues&#34; includes these columns as well &ndash; see <a href="ch4scenarios.htm#BABCGFIJ">&#34;Database Scan Report: Filtering&#34;</a>.</p>
<p>The View Data tab, described in <a href="ch6cleansing.htm#BCGBHDHE">&#34;Viewing Data&#34;</a>, which is a read-only version of the Cleansing Editor for data dictionary and other non-modifiable tables, shows convertible values in non-convertible data dictionary columns in dedicated colors configured on the Cleansing Editor tab in the Preferences dialog box, by default black on orange background.</p>
<p>Convertible data in the few columns that the DMU does convert, which are listed in <a href="#CIHDDJDB">&#34;Converting Data Dictionary Tables&#34;</a>, is not reported as an issue.</p>
<p>For implementation reasons, the tables <code dir="ltr">SYS.SOURCE$</code>, <code dir="ltr">SYS.ARGUMENT$</code>, <code dir="ltr">SYS.IDL_CHAR$</code>, <code dir="ltr">SYS.VIEW$</code>, <code dir="ltr">SYS.PROCEDUREINFO$</code>, and <code dir="ltr">SYS.PLSCOPE_IDENTIFIER$</code> are always scanned with &#34;Rowids to Collect&#34; parameter set to &#34;All to Convert&#34;. See <a href="#CIHDDJDB">&#34;Converting Data Dictionary Tables&#34;</a> for more details.</p>
</div>
<!-- class="sect2" -->
<a id="CIHHJHHA"></a>
<div id="DUMAG363" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Cleansing Data Dictionary Tables</h3>
<p>As Oracle neither supports altering structure of data dictionary tables nor updating their contents, the DMU does not allow cleansing actions on such tables. You can set the assumed character set of columns of the data dictionary tables but the selected character set is considered only when displaying the columns on the View Data tab. The source character set used for conversion is always the assumed database character set.</p>
<div id="DUMAG364" class="sect3"><!-- infolevel="all" infotype="General" --><a id="sthref194"></a>
<h4 class="sect3">Cleansing Data Length Issues</h4>
<p>If data length issues are re<a id="sthref195"></a>ported for data dictionary contents, that is, the metadata, the only way to cleanse the issues is to replace the metadata with its shorter version. The same length issues affect all character set migration methods, not only migration with the DMU, so you must cleanse the issues even if you plan to use alternative conversion methods, such as moving data with the Data Pump utilities.</p>
<p>The most common length issues are object names becoming longer than allowed after conversion. As the usual length limit for an identifier is only 30 bytes, longer identifiers containing non-ASCII letters, especially those written in non-Latin scripts, may easily exceed the limit. For example, a Greek or Russian identifier longer than 15 characters will not fit into the 30 bytes limit after conversion from EL8MSWIN1253 or CL8MSWIN1251 to UTF8 or AL32UTF8. Chinese, Japanese, and Korean characters usually expand from 2 to 3 bytes, so identifiers longer than 10 characters become an issue.</p>
<p>To shorten an identifier, you must rename the corresponding database object with an appropriate SQL statement or a PL/SQL package call. Some objects can be just renamed but most have to be dropped and re-created under the new name. When you drop an object, some dependent objects may be dropped along. You must re-create them as well.</p>
<p>For example, you can rename a table, a view, a sequence, or a private synonym using the SQL statement <code dir="ltr">RENAME</code>. You can rename a table column using the SQL statement <code dir="ltr">ALTER</code> <code dir="ltr">TABLE</code> <code dir="ltr">RENAME</code> <code dir="ltr">COLUMN</code>. But you cannot simply rename a cluster. You must drop it and re-create under another name. But before you drop a cluster, you must drop all tables stored in the cluster. As there are many possible auxiliary objects created for tables, such as privileges, indexes, triggers, row-level security policies, outlines, and so on, you may end up re-creating a lot of objects. The Data Pump utilities and the Metadata API may be helpful in such case.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a class="olink SUTIL100" href="../SUTIL/GUID-17FAE261-0972-4220-A2E4-44D479F519D4.htm#SUTIL100"><span class="italic">Oracle Database Utilities</span></a> for more information about the Data Pump utilities and the Metadata API</div>
<p>After renaming a database object, you must change all application code that references this object to use the new name. This includes PL/SQL and Java code in the database, but also all affected client applications.</p>
<p>Another type of metadata that often expands beyond maximum allowed length is free text comments for various database objects. Similarly, you must update the comments with a shorter version to cleanse any reported length issues. Most comments can be updated with an appropriate SQL statement or PL/SQL package call.</p>
<p>See <a href="#CIHFBJCG">&#34;Identifying Metadata&#34;</a> for suggestions about identifying right statements to cleanse data dictionary issues.</p>
</div>
<!-- class="sect3" -->
<div id="DUMAG365" class="sect3"><!-- infolevel="all" infotype="General" --><a id="sthref196"></a>
<h4 class="sect3">Cleansing Invalid Binary Representation Issues</h4>
<p>A common re<a id="sthref197"></a>ason for invalid binary representation of data is the pass-through scenario, described in <a href="ch1overview.htm#CJAHJBDG">&#34;Invalid Binary Storage Representation of Data&#34;</a>. If SQL statements or PL/SQL calls are issued in such a configuration, it is possible to create and use a database object that is named using or contains characters not valid or not having the expected meaning in the database character set. For example, a seemingly senseless table name in a WE8MSWIN1252 database might be interpreted as appearing correct on a Japanese JA16SJIS client, or, a PL/SQL module might contain comments that are not legible in the database character set but that make sense when viewed in another character set.</p>
<p>Invalid binary representation of database object names is a seldom encountered issue as restrictions on characters allowed in non-quoted identifiers make it visible from the very beginning. Invalid binary representation of object comments is more probable but also easier to fix.</p>
<p>To cleanse the invalid binary representation issues caused by the pass-through configuration, if they are common to the application data as well, set the assumed database character set property of the database to the real character set of the database contents &ndash; see <a href="ch3tasks.htm#BABDHECD">&#34;Database Properties: General&#34;</a>. Otherwise, use the same approach that is described in <a href="#CIHHJHHA">&#34;Cleansing Data Dictionary Tables&#34;</a> to update the affected metadata with a version that does not have convertibility issues.</p>
<p>To fix invalid representation issues in PL/SQL and Java source code or in view definitions, use Metadata API to retrieve the DDL statements creating the objects, correct the problematic characters in the statement text and execute the statements to re-create the objects. If object names are not affected, use the <code dir="ltr">CREATE</code> <code dir="ltr">OR</code> <code dir="ltr">REPLACE</code> syntax to change the code without having to re-create related objects, such as privileges.</p>
</div>
<!-- class="sect3" -->
<a id="CIHFBJCG"></a>
<div id="DUMAG366" class="sect3"><!-- infolevel="all" infotype="General" -->
<h4 class="sect3">Identifying Metadata</h4>
<p>A difficult step in the process of resolving data dictionary convertibility issues is to map the issues shown in a database scan report to the type of metadata that is stored in the affected tables and columns. The data dictionary tables, presented in the DMU interface, are generally not documented. The documented way to view their contents is through data dictionary views such as <code dir="ltr">DBA_TABLES</code>, <code dir="ltr">DBA_TAB_COLUMNS</code>, <code dir="ltr">DBA_RULES</code>, <code dir="ltr">DBA_SCHEDULER_JOBS</code>, and many others.</p>
<p>To identify the type of metadata that has convertibility issues, try one of the methods below, in the presented order:</p>
<ul>
<li>
<p>Look at the problematic character value on the View Data tab &ndash; see <a href="ch6cleansing.htm#BCGBHDHE">&#34;Viewing Data&#34;</a>. The value itself may already tell you the metadata that it belongs to. For example, the value may be &#34;This column keeps customer e-mail&#34;, which suggests that it is a column comment, or it may be &#34;HR_EMPLOYEE_V&#34;, which may correspond to a common convention to name views, thus showing the value is a view name.</p>
</li>
<li>
<p>Search for the name of the table in which the issues are reported in SQL script files named <code dir="ltr">cat*.sql</code> and <code dir="ltr">cd*.sql</code> and located in the <code dir="ltr">rdbms/admin/</code> subdirectory of your database Oracle home directory. These scripts define data dictionary views that are documented in <a class="olink REFRN002" href="../REFRN/GUID-8865F65B-EF6D-44A5-B0A1-3179EFF0C36A.htm#REFRN002"><span class="italic">Oracle Database Reference</span></a>. By mapping the table and its columns to the right documented view, you can find out which metadata has the reported issues.</p>
</li>
<li>
<p>Contact Oracle Support or post a question on the globalization forum on the Oracle Technology Network Web site.</p>
</li>
</ul>
<p>Once you identified the metadata that has the reported convertibility issues, refer to Oracle documentation to identify the right procedure to change this metadata.</p>
</div>
<!-- class="sect3" --></div>
<!-- class="sect2" -->
<a id="CIHDDJDB"></a>
<div id="DUMAG367" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Converting Data Dictionary Tables</h3>
<p>The DMU conver<a id="sthref198"></a><a id="sthref199"></a>ts only the following data in the data dictionary:</p>
<ul>
<li>
<p><code dir="ltr">CLOB</code> columns &ndash; this is necessary only in a single-byte database</p>
</li>
<li>
<p>Binary XML token manager tables, with names like <code dir="ltr">XDB.X$QN%</code> and <code dir="ltr">XDB.X$NM%</code></p>
</li>
<li>
<p>PL/SQL source code (text of <code dir="ltr">CREATE</code> <code dir="ltr">PROCEDURE</code>, <code dir="ltr">CREATE</code> <code dir="ltr">FUNCTION</code>, <code dir="ltr">CREATE</code> <code dir="ltr">PACKAGE</code>, <code dir="ltr">CREATE</code> <code dir="ltr">PACKAGE</code> <code dir="ltr">BODY</code>, <code dir="ltr">CREATE</code> <code dir="ltr">TYPE</code> <code dir="ltr">BODY</code>, <code dir="ltr">CREATE</code> <code dir="ltr">TRIGGER</code>, and <code dir="ltr">CREATE</code> <code dir="ltr">LIBRARY</code>); type specifications (<code dir="ltr">CREATE</code> <code dir="ltr">TYPE</code>) are not converted</p>
</li>
<li>
<p>View definitions (text of <code dir="ltr">CREATE</code> <code dir="ltr">VIEW</code>)</p>
</li>
<li>
<p>The columns:</p>
<ul>
<li>
<p><code dir="ltr">SYS.SCHEDULER$_JOB.NLS_ENV</code> &ndash; NLS environment for Database Scheduler jobs (<code dir="ltr">DBMS_SCHEDULER</code>)</p>
</li>
<li>
<p><code dir="ltr">SYS.SCHEDULER$_PROGRAM.NLS_ENV</code> - NLS environment for Database Scheduler job programs (<code dir="ltr">DBMS_SCHEDULER</code>)</p>
</li>
<li>
<p><code dir="ltr">SYS.JOB$.NLS_ENV</code> &ndash; NLS environment for legacy jobs (<code dir="ltr">DBMS_JOB</code>)</p>
</li>
<li>
<p><code dir="ltr">CTXSYS.DR$INDEX_VALUE.IXV_VALUE</code> - attribute values of Oracle Text policies</p>
</li>
<li>
<p><code dir="ltr">CTXSYS.DR$STOPWORD.SPW_WORD</code> - all stopwords in all stoplists of Oracle</p>
</li>
<li>
<p>over 50 different columns in <code dir="ltr">SYS</code>, <code dir="ltr">SYSTEM</code>, and <code dir="ltr">CTXSYS</code> schemas that contain user comments for various database objects</p>
</li>
</ul>
<p>The PL/SQL source code and the view source text are kept in multiple tables. The DMU checks the following columns when processing the source code and view definitions:</p>
<ul>
<li>
<p><code dir="ltr">SYS.VIEW$.TEXT</code> &ndash; view definition text</p>
</li>
<li>
<p><code dir="ltr">SYS.SOURCE$.SOURCE</code> &ndash; PL/SQL and Java source code</p>
</li>
<li>
<p><code dir="ltr">SYS.ARGUMENT$.PROCEDURE$</code> &ndash; PL/SQL argument definitions: procedure name</p>
</li>
<li>
<p><code dir="ltr">SYS.ARGUMENT$.ARGUMENT</code> &ndash; PL/SQL argument definitions: argument name</p>
</li>
<li>
<p><code dir="ltr">SYS.ARGUMENT.DEFAULT$</code> &ndash; PL/SQL argument definitions: default value</p>
</li>
<li>
<p><code dir="ltr">SYS.PROCEDUREINFO$.PROCEDURENAME</code> - names of procedures and functions declared in packages</p>
</li>
<li>
<p><code dir="ltr">SYS.IDL_CHAR$.PIECE</code> - internal representation of PL/SQL</p>
</li>
<li>
<p><code dir="ltr">SYS.PLSCOPE_IDENTIFIER$.SYMREP</code> - internal representation of PL/SQL; this table did not exist before version 11.1 of Oracle Database</p>
</li>
</ul>
<p>The DMU does not report convertible character data in the tables and columns listed above as a convertibility issue. Any convertible data in the remaining tables and columns of the data dictionary is flagged as a convertibility issue in scan reports and on the Migration Status tab. The database conversion step cannot be started before the flagged data is removed.</p>
</li>
</ul>
</div>
<!-- class="sect2" -->
<a id="CIHEIJDC"></a>
<div id="DUMAG368" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Data Dictionary Tables That Are Ignored</h3>
<p>The DMU does not scan the following tables:</p>
<ul>
<li>
<p><code dir="ltr">SYS.HISTGRM$</code>, which contains column histogram statistics</p>
</li>
<li>
<p>Automatic Workload Repository object statistics history kept in tables with names such as <code dir="ltr">SYS.WRI$_OPTSTAT_OPR</code> and <code dir="ltr">SYS.WRI$_OPTSTAT_%_HISTORY</code></p>
</li>
<li>
<p>DMU repository tables in the <code dir="ltr">SYSTEM</code> schema</p>
</li>
<li>
<p><code dir="ltr">CSSCAN</code> repository tables in the <code dir="ltr">CSMIG</code> schema</p>
</li>
</ul>
<p>The contents of these tables are also not considered when the DMU decides if the database conversion is allowed to start.</p>
<p>The <code dir="ltr">SYS.HISTGRM$</code> table is not scanned because its <code dir="ltr">EPVALUE</code> column (storing end-point values) may contain binary data. As histograms and other table statistics depend on binary representation of data in character columns, you should anyway re-gather statistics for all converted tables in the database after migration. Collection of statistics refreshes the contents of the <code dir="ltr">SYS.HISTGRM$</code> table and revalidates it in the new database character set. If you do not refresh the statistics, the optimizer may exhibit incorrect behavior.</p>
<p>Similarly, the historical object statistics kept in Automatic Workload Repository become stale after the migration because they also depend on binary representation of character data. The DMU does not migrate those statistics. You should purge them manually after migration by calling <code dir="ltr">DBMS_STATS.PURGE_STATS(SYSTIMESTAMP)</code>.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<ul>
<li>
<p><a class="olink ARPLS059" href="../ARPLS/d_stats.htm#ARPLS059"><span class="italic">Oracle Database PL/SQL Packages and Types Reference</span></a> for more information about the package <code dir="ltr">DBMS_STATS</code> and the procedure <code dir="ltr">PURGE_STATS</code></p>
</li>
<li>
<p><a class="olink CNCPT88915" href="../CNCPT/sqllangu.htm#CNCPT88915"><span class="italic">Oracle Database Concepts</span></a> for more information about optimizer statistics</p>
</li>
</ul>
</div>
<p>The DMU and <code dir="ltr">CSSCAN</code> repository data becomes invalid after the database is migrated to a new database character set. Therefore, there is no point in migrating it along with the database. After the migration, you should drop the repositories and re-create them, if you still need them. If you re-create the DMU repository after migration, choose the validation mode &ndash; see <a href="ch4scenarios.htm#CIHJJEJD">&#34;Validating Data as Unicode&#34;</a>.</p>
</div>
<!-- class="sect2" -->
<div id="DUMAG1520" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref200"></a>
<h3 class="sect2">Handling Automatic Workload Repository Tables</h3>
<p>The <code dir="ltr">SYS</code> schema contains a number of tables with names beginning with <code dir="ltr">WRI$</code>, <code dir="ltr">WRH$%</code>, and <code dir="ltr">WRR$_</code>, which comprise the Automatic Workload Repository (AWR). In addition to historical object statistics, mentioned in <a href="#CIHEIJDC">&#34;Data Dictionary Tables That Are Ignored&#34;</a>, this repository stores snapshots of vital system statistics, such as those visible in various fixed views, for example, <code dir="ltr">V$SYSSTAT</code> and <code dir="ltr">V$SQLAREA</code>.</p>
<p>If non-ASCII characters are used in object names or in SQL statements, such as character literals or comments, they may get captured into the AWR tables. The DMU scan will report such characters as convertible data dictionary content, which prevents conversion of the database. To remove this data completely, re-create the Automatic Workload Repository by logging into SQL*Plus with <code dir="ltr">SYSDBA</code> privileges and running:</p>
<pre dir="ltr">SQL&gt; @?/rdbms/admin/catnoawr.sql
SQL&gt; @?/rdbms/admin/catawr.sql
</pre>
<p>As the <code dir="ltr">catawr.sql</code> script is not present in Oracle Database versions 10.2.0.4 and earlier, Oracle recommends that you install the Oracle Database patch set 10.2.0.5 before purging AWR contents.</p>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="CIHDGGCE"></a>
<div id="DUMAG369" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">Working with Multilingual Columns</h2>
<p>As m<a id="sthref201"></a>entioned in <a href="ch6cleansing.htm#BACBICBI">&#34;Cleansing Incorrect Character Set Declaration&#34;</a>, you may find out while analyzing contents of a column in the Cleansing Editor that none of the assumed character sets set for the column makes all values in the column appear correctly at the same time, but each of the values does seem to be correct in one of the selected character sets. This indicates that the column contains a mixture of data in different character sets. You might also gather this information from analysis of data sources for your database.</p>
<p>Multiple character sets in a single column are possible in the pass-through scenario, if clients working in various character sets all store data in this column.</p>
<p>This release of the DMU does not contain any feature dedicated to cleansing this type of convertibility issue. The following procedure is recommended when you must deal with multiple character sets in a single <code dir="ltr">CHAR</code> or <code dir="ltr">VARCHAR2</code> column:</p>
<p class="subhead2"><a id="DUMAG1441"></a>To work with multiple character sets in a single CHAR or VARCHAR2 column:</p>
<ol>
<li>
<p>Find any auxiliary data that can help you identify the real character set of a single value in an affected column. Examples of such data are:</p>
<ul>
<li>
<p>a country code associated with the value</p>
</li>
<li>
<p>an identifier of the operator who entered the value</p>
</li>
<li>
<p>an identifier of a subsidiary responsible for entering the value</p>
</li>
</ul>
</li>
<li>
<p>Create a mapping table that maps auxiliary data to possible character sets of the values. If your company standardizes on a certain type of workstations, the source country of the analyzed value usually defines the client character set used to enter the value.</p>
</li>
<li>
<p>Mark columns that contain data in multiple character sets for exclusion from conversion &ndash; see <a href="ch3tasks.htm#BABEBIEH">&#34;Column Properties: Converting&#34;</a>.</p>
</li>
<li>
<p>Verify that there are no length issues with the columns. If required, cleanse them by making longer or by shortening problematic values. Do not migrate to <code dir="ltr">CLOB</code>. See <a href="#CIHJFABA">Example 5-1</a> below for information about how to check for length issues.</p>
</li>
<li>
<p>Convert the database.</p>
</li>
<li>
<p>Using the mapping table, convert the affected columns with the SQL function <code dir="ltr">CONVERT</code> specifying the target Unicode character set in its second argument and the identified value character set in its third argument.</p>
</li>
</ol>
<div id="DUMAG370" class="example">
<p class="titleinexample"><a id="CIHJFABA"></a>Example 5-1 Multilingual Column Considerations</p>
<p>Assume your database contains the table <code dir="ltr">CUSTOMERS</code>, with columns <code dir="ltr">CUSTOMER_NAME_ORIGINAL</code> and <code dir="ltr">CREATED_BY</code>. The column <code dir="ltr">CUSTOMER_NAME_ORIGINAL</code>, defined as <code dir="ltr">VARCHAR2(80 BYTE)</code>, contains the names of customers in their mother tongue in multiple character sets. The column <code dir="ltr">CREATED_BY</code> contains system IDs of employees who entered the customer data. You want to migrate the database to the character set AL32UTF8.</p>
<p>To solve the issue of multiple character sets in the <code dir="ltr">CUSTOMER_NAME_ORIGINAL</code> column start with creating a mapping table that maps employees&#39; system IDs to client character sets of the employees&#39; workstations. A table in your application that defines the system IDs may be helpful in locating the country in which the employee works and thus determining the character set of the client workstation that the employee uses. Further assume the created mapping table is named <code dir="ltr">CREATED_BY_TO_CHARSET_MAPPING</code> and has the columns <code dir="ltr">CREATED_BY</code> and <code dir="ltr">CHARACTER_SET</code>. The contents of such a table might resemble the following:</p>
<pre dir="ltr">CREATED_BY    CHARACTER_SET
----------    -------------
...
JSMITH        WE8MSWIN1252
JKOWALSKI     EE8MSWIN1250
SKUZNETSOV    CL8MSWIN1251
WLI           ZHS16GBK
...
</pre>
<p>Now, set the Exclude from Conversion property of the <code dir="ltr">CUSTOMER_NAME_ORIGINAL</code> column to Yes to prevent data from being corrupted while the rest of the database is converted.</p>
<p>Check for possible length issues in <code dir="ltr">CUSTOMER_NAME_ORIGINAL</code> by running the following SQL:</p>
<pre dir="ltr">SELECT c.ROWID
  FROM customers c, created_by_to_charset_mapping csm
 WHERE VSIZE(CONVERT(c.customer_name_original,
                         &#39;AL32UTF8&#39;,
                         csm.character_set)) &gt; 80
   AND c.created_by = csm.created_by
</pre>
<p>If no rows are returned, there are no length issues. Otherwise, the returned rowids will help you locate the problematic values.</p>
<p>When the database is ready, convert it to AL32UTF8. Change the application configuration as required for the new database character set.</p>
<p>After the database conversion, run the following update statement:</p>
<pre dir="ltr">UPDATE customers c
    SET c.customer_name_original =
         (SELECT CONVERT(c.customer_name_original,
                            &#39;AL32UTF8&#39;,
                            csm.character_set)
            FROM created_by_to_charset_mapping csm
           WHERE csm.created_by = c.created_by)
</pre>
<p>This will convert the individual values of the column according to their assumed character set. Let employees who entered the customer data or who speak the relevant languages verify the post-conversion values for correctness.</p>
</div>
<!-- class="example" --></div>
<!-- class="sect1" -->
<a id="CIHEJAIG"></a>
<div id="DUMAG371" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">Advanced Convertibility Issues</h2>
<p>This section describes less frequently encountered convertibility issues that are not currently handled automatically by the DMU and might require that you perform additional scanning and cleansing steps outside of the tool.</p>
<p>It contains these topics:</p>
<ul>
<li>
<p><a href="#CIHHHJCG">Convertibility Issues: Uniqueness Validation</a></p>
</li>
<li>
<p><a href="#CIHCDJHI">Convertibility Issues: Index Size</a></p>
</li>
<li>
<p><a href="#CIHJAAFH">Convertibility Issues: Partition Range Integrity</a></p>
</li>
<li>
<p><a href="#CIHBCBHF">Convertibility Issues: Objects in the Recycle Bin</a></p>
</li>
<li>
<p><a href="#CIHEBHIE">Convertibility Issues: PL/SQL Local Identifiers Greater Than 30 Bytes</a></p>
</li>
</ul>
<a id="CIHHHJCG"></a>
<div id="DUMAG372" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Convertibility Issues: Uniqueness Validation</h3>
<p>There are two<a id="sthref202"></a><a id="sthref203"></a> situations when some rows in a table might no longer satisfy a unique or primary key constraint after database contents have been converted to Unicode:</p>
<ul>
<li>
<p>A unique or primary key column has data with length issues, that is, some values expand in conversion beyond the column or data type length limit, and you set the property &#34;Allow Conversion of Data with Issues&#34; of this column to Yes. In such a case, the DMU will automatically truncate column values during the conversion step so that they fit into the existing length constraint. However, a truncated value may become identical with another value already in the column from which it differed only be the truncated suffix.</p>
</li>
<li>
<p>In various Oracle character sets, there are multiple character codes that map to a single Unicode code point. This is usually a result of:</p>
<ul>
<li>
<p>an attempt to provide compatibility mapping for historical changes to a character set definition or to its interpretation by different vendors</p>
</li>
<li>
<p>an attempt to provide simplified mapping for codes that cannot be exactly mapped to Unicode, for example, because the actual mapping consists of a sequence of Unicode codes, and this is not supported by Oracle&#39;s conversion architecture</p>
</li>
<li>
<p>Unicode Standard unification rules, which cause certain groups of Han (Chinese) characters to get a single code point assigned, even though characters in such a group may be separately encoded in legacy East Asian character sets</p>
</li>
</ul>
<p>If two character values in a single column differ only by characters that have the same mapping to Unicode in the assumed character set of the column, they become identical after conversion to Unicode.</p>
<p>The following character sets supported by the DMU have multiple codes that map to the same Unicode code point:</p>
<ul>
<li>
<p>BG8PC437S</p>
</li>
<li>
<p>IW8MACHEBREW</p>
</li>
<li>
<p>IW8MACHEBREWS</p>
</li>
<li>
<p>JA16EUCTILDE</p>
</li>
<li>
<p>JA16MACSJIS</p>
</li>
<li>
<p>JA16SJIS</p>
</li>
<li>
<p>JA16SJISTILDE</p>
</li>
<li>
<p>JA16SJISYEN</p>
</li>
<li>
<p>JA16VMS</p>
</li>
<li>
<p>KO16KSCCS</p>
</li>
<li>
<p>LA8ISO6937</p>
</li>
<li>
<p>ZHS16MACCGB231280</p>
</li>
<li>
<p>ZHT16BIG5</p>
</li>
<li>
<p>ZHT16CCDC</p>
</li>
<li>
<p>ZHT16HKSCS</p>
</li>
<li>
<p>ZHT16HKSCS31</p>
</li>
<li>
<p>ZHT16MSWIN950</p>
</li>
</ul>
<p>You can use the Oracle Locale Builder utility to check which character codes are affected. See <a class="olink NLSPG" href="../NLSPG/toc.htm"><span class="italic">Oracle Database Globalization Support Guide</span></a> for more information about this utility.</p>
<p>If you suspect that a unique or primary key constraint might be affected by one of the above two issues, you can verify if you indeed have a problem by attempting to create an appropriate unique functional index. For example, if you have a unique or primary key constraint on character columns <code dir="ltr">tab1.col1</code> and <code dir="ltr">tab1.col2</code> and a numeric column <code dir="ltr">tab1.col3</code>, attempt to create the following index:</p>
<pre dir="ltr">CREATE UNIQUE INDEX i_test
  ON tab1(SYS_OP_CSCONV(col1,&#39;AL32UTF8&#39;,&#39;&lt;assumed character set of col1&gt;&#39;),
           SYS_OP_CSCONV(col2,&#39;AL32UTF8&#39;,&#39;&lt;assumed character set of col2&gt;&#39;),
           col3)
  TABLESPACE ...
</pre>
<p>Substitute <code dir="ltr">&#39;UTF8&#39;</code> for <code dir="ltr">&#39;AL32UTF8&#39;</code>, if this is the actual target character set. The third parameter to <code dir="ltr">SYS_OP_CSCONV</code> may be omitted, if the assumed character set of a column is the same as the database character set (default). If the statement fails reporting &#34;ORA-01452: cannot CREATE UNIQUE INDEX; duplicate keys found&#34;, there is a uniqueness problem in the column.</p>
<p>The <code dir="ltr">CREATE</code> <code dir="ltr">INDEX</code> statement above assumes that you do not plan any scheduled lengthening of the columns and the columns are not defined using character length semantics. If you plan to extend <code dir="ltr">col1</code> to <span class="italic">n1</span> bytes and <code dir="ltr">col2</code> to <span class="italic">n2</span> bytes, use the following statement:</p>
<pre dir="ltr">CREATE UNIQUE INDEX i_test
  ON tab1(SYS_OP_CSCONV(SUBSTRB(RPAD(col1,n1,&#39; &#39;),1,n1),
                            &#39;AL32UTF8&#39;,&#39;&lt;assumed character set of col1&gt;&#39;),
           SYS_OP_CSCONV(SUBSTRB(RPAD(col2,n2,&#39; &#39;),1,n2),
                            &#39;AL32UTF8&#39;,&#39;&lt;assumed character set of col2&gt;&#39;),
           col3)
  TABLESPACE ...;
</pre>
<p>Substitute <code dir="ltr">&#39;UTF8&#39;</code> for <code dir="ltr">&#39;AL32UTF8</code>&#39;, if the target character set is UTF8.</p>
<p>If <code dir="ltr">col1</code> and <code dir="ltr">col2</code> are defined using character length semantics and their character lengths are, respectively, <span class="italic">n1</span> and <span class="italic">n2</span>, use the following statement:</p>
<pre dir="ltr">CREATE UNIQUE INDEX i_test
  ON tab1(SYS_OP_CSCONV(SUBSTRB(RPAD(col1,4*n1,&#39; &#39;),1,4*n1),
                            &#39;AL32UTF8&#39;,&#39;&lt;assumed character set of col1&gt;&#39;),
           SYS_OP_CSCONV(SUBSTRB(RPAD(col2,4*n2,&#39; &#39;),1,4*n2),
                            &#39;AL32UTF8&#39;,&#39;&lt;assumed character set of col2&gt;&#39;),
           col3)
  TABLESPACE ...;
</pre>
<p>Substitute <code dir="ltr">&#39;UTF8&#39;</code> for <code dir="ltr">&#39;AL32UTF8&#39;</code> and 3* for 4*, if the target character set is UTF8.</p>
</li>
</ul>
</div>
<!-- class="sect2" -->
<a id="CIHCDJHI"></a>
<div id="DUMAG373" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Convertibility Issues: Index Size</h3>
<p>The maximum size of an inde<a id="sthref204"></a>x key in an Oracle database index &ndash; that is, the sum of maximum byte lengths of all key columns plus rowid length plus the number of length bytes &ndash; cannot exceed the data block size in the tablespace of the index minus around 25% overhead.</p>
<p>If the maximum byte length of a character column belonging to an index key increases during database conversion, either because:</p>
<ul>
<li>
<p>it is being recalculated from the column character length for the new database character set</p>
<p>or</p>
</li>
<li>
<p>a lengthening cleansing action is defined on the column</p>
</li>
</ul>
<p>The maximum byte length may cause the index key to exceed its allowed maximum length.</p>
<p>In this release, the DMU does not proactively verify index key lengths that change in the conversion step. Therefore, &#34;ORA-01450: maximum key length (maximum) exceeded&#34; or &#34;ORA-01404: ALTER COLUMN will make an index too large&#34; may be reported during conversion from an <code dir="ltr">ALTER</code> <code dir="ltr">TABLE</code>, <code dir="ltr">CREATE</code> <code dir="ltr">INDEX</code>, or <code dir="ltr">ALTER</code> <code dir="ltr">DATABASE</code> <code dir="ltr">CHARACTER</code> <code dir="ltr">SET</code> statement.</p>
<p>Before attempting conversion, you should review all indexes defined on <code dir="ltr">VARCHAR2</code> and <code dir="ltr">CHAR</code> columns that have a lengthening cleansing actions scheduled or that use character length semantics to verify that they are not affected by this issue. The easiest approach is to test the migration on a copy of the original database. The copy should include the DMU repository with all planned cleansing actions. The actual application data does not affect the test so you can truncate all large convertible tables to shorten the test time.</p>
</div>
<!-- class="sect2" -->
<a id="CIHJAAFH"></a>
<div id="DUMAG374" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Convertibility Issues: Partition Range Integrity</h3>
<p>While the DMU doe<a id="sthref205"></a>s not support converting a database in which any partition bounds require conversion, you may want to migrate such a database using Data Pump utilities. While preparing for the migration process, you should consider the following potential issues with partition integrity.</p>
<p>Oracle Database distributes table rows among range partitions by comparing values of the partitioning key columns with partition bounds. This comparison uses binary sort order, that is, the byte representations of values, as stored on disk, are compared byte by byte. With character columns, the representation depends on the database character set and may change in conversion to Unicode. If the binary representation of partition bounds changes, the partitions might get reordered and the distribution of rows among partitions might change significantly.</p>
<p>You should analyze all range partitioned tables with convertible data in partitioning columns and, if required, adjust their partition definitions, so that rows are still distributed according to your expectations after the database migration to Unicode.</p>
<p>While very improbable, partition range bounds and partition list values may also suffer from the uniqueness issue described in <a href="#CIHHHJCG">&#34;Convertibility Issues: Uniqueness Validation&#34;</a>. If such an issue is encountered for a partitioned table, the table cannot be imported successfully without partition definitions being adjusted accordingly.</p>
</div>
<!-- class="sect2" -->
<a id="CIHBCBHF"></a>
<div id="DUMAG375" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Convertibility Issues: Objects in the Recycle Bin</h3>
<p>The DMU scans chara<a id="sthref206"></a>cter columns in tables that have been dropped and are in the recycle bin like normal tables. Their scan results are included in the database scan report. Unlike the normal application tables, the dropped tables in recycle bin are not allowed to contain data that requires conversion. You cannot start the conversion step until tables with convertible data are removed from the recycle bin.</p>
<p>No cleansing actions are supported on dropped tables.</p>
</div>
<!-- class="sect2" -->
<a id="CIHEBHIE"></a>
<div id="DUMAG376" class="sect2"><!-- infolevel="all" infotype="General" -->
<h3 class="sect2">Convertibility Issues: PL/SQL Local Identifiers Greater Than 30 Bytes</h3>
<p>While the DMU<a id="sthref207"></a> does not support converting names of PL/SQL stored modules, that is, stored procedures, stored functions and packages, it does automatically convert PL/SQL source code and view definitions including non-ASCII characters in:</p>
<ul>
<li>
<p>names of procedures, functions, and types defined in packages</p>
</li>
<li>
<p>local identifiers, such as variable names and type names</p>
</li>
<li>
<p>character literals</p>
</li>
<li>
<p>comments</p>
</li>
</ul>
<p>In the conversion step, the DMU fetches the relevant <code dir="ltr">CREATE</code> <code dir="ltr">OR</code> <code dir="ltr">REPLACE</code> <code dir="ltr">PACKAGE</code>|<code dir="ltr">PACKAGE</code> <code dir="ltr">BODY</code>|<code dir="ltr">PROCEDURE</code>|<code dir="ltr">FUNCTION</code>|<code dir="ltr">TYPE</code>|<code dir="ltr">TYPE</code> <code dir="ltr">BODY</code>|<code dir="ltr">VIEW</code> statements from the data dictionary, converts them to the target character set and, after the database character set has been changed to UTF8 or AL32UTF8, executes them.</p>
<p>The DMU does not check if any converted identifier exceeds its length constraint (usually 30 bytes). If an identifier becomes longer than allowed after conversion to Unicode, the resulting PL/SQL module will be created but its compilation will fail, usually reporting &#34;PLS-00114: identifier &#39;&lt;<span class="italic">identifier</span>&gt;&#39; too long&#34;. The status of the module will be &#34;invalid&#34;.</p>
<p>You should verify the status of all PL/SQL stored modules after the database conversion. If any module is in the invalid state because of an identifier being too long, you must manually shorten the identifier &ndash; in its definition and in all places where it is referenced.</p>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="CIHEIHIF"></a>
<div id="DUMAG377" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">Adapting Applications for Unicode Migration</h2>
<p>The migration of a<a id="sthref208"></a><a id="sthref209"></a> database to Unicode always impacts applications connecting to this database. The scale of the impact depends on multiple factors, such as the following:</p>
<ul>
<li>
<p>Do you want the applications to process new languages, which the database will now be able to store?</p>
<p>Support for new languages usually entails the need to adapt applications to process Unicode data. Applications that have been programmed to process only single-byte character sets will need significant changes to be able to process the full Unicode character repertoire. On the other hand, applications that will work with the same limited number of characters as before may require only minimal changes, taking advantage of Oracle client/server character set conversion.</p>
</li>
<li>
<p>Will languages with complex scripts require GUI support from the applications?</p>
<p>Complex script-rendering capabilities are necessary to display and accept text written in complex scripts, such as Arabic or Indian. Complex rendering includes, among other requirements, combining adjacent characters, where some fragments read from right-to-left, while some are left-to-right, as well as changing character shape depending on the character&#39;s position in a word.</p>
</li>
<li>
<p>What technologies are the applications built with?</p>
<p>Depending on the development framework in which the applications have been developed, modifying them to accept new languages may be relatively easy or very difficult. Fortunately, most modern environments, such as Java or Microsoft Windows, offer built-in or installable support for complex script rendering and Unicode processing. Applications can take advantage of this support, which simplifies the adaptation process, but does not eliminate it.</p>
</li>
<li>
<p>Are the applications developed in-house or by a third-party vendor?</p>
<p>Obviously, you can adapt only those applications of which you have the source code. Applications developed by vendors must be adapted by those vendors. If this turns out to be impossible, you may have to replace your applications with another software solution.</p>
</li>
</ul>
<p>In addition to these considerations, requirements to make migration-related changes to applications can result from:</p>
<ul>
<li>
<p>Table structure changes coming from cleansing actions, columns being lengthened or migrated to another data type.</p>
</li>
<li>
<p>Changed characteristics of the database character set, such as higher maximum byte width of a character.</p>
</li>
<li>
<p>Additional requirements of the new languages to be processed. This might include new sorting rules, new date or number formatting rules, non-Gregorian calendar support, and so on.</p>
</li>
<li>
<p>Changed binary sort order of strings in Unicode compared to the old legacy character set.</p>
</li>
</ul>
<p>Details of adapting applications for new languages exceed the scope of this guide, but the following sections describe the minimal changes that may be required to continue running existing applications with a migrated database.</p>
<div id="DUMAG378" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref210"></a>
<h3 class="sect2">Running Legacy Applications Unchanged</h3>
<p>You might want to run some of your existing applications unchanged after migration of their back-end database to Unicode. For example, you might not have access to the source code of the applications to adapt them for Unicode or modifying the applications may be economically unjustified.</p>
<p>The main requirement for running an application unchanged after migration of its back-end database to Unicode is that all Unicode characters that the application may encounter also exist in a legacy character set for which the application was originally written. That is, if the application was written, for example, to process only the ISO 8859-1 standard character set (WE8ISO8859P1), then only the corresponding Unicode characters U+0000 - U+007F and U+00A0 - U+00FF are allowed in the subset of database contents accessed by the application.</p>
<p>If this requirement is fulfilled, the client character set for the application, as specified in the <code dir="ltr">NLS_LANG</code> environment setting, shall be set to the above legacy character set (in practice, it usually means that <code dir="ltr">NLS_LANG</code> remains the sam before and after the migration) and the client/server communication protocol will take care of converting character data between the legacy encoding used by the application and the Unicode encoding used by the database.</p>
<p>If the only characters processed by an application are standard US7ASCII characters, the application does not require any modification at all, because UTF8 and AL32UTF8 binary codes of all ASCII characters are identical to US7ASCII. Therefore, the processed bytes do not differ before and after the database character set migration.</p>
<p>Binary codes of characters outside of the ASCII range - for example, accented Latin letters - remain the same on the client side but change on the database side after the database character set change. The most important difference is usually the number of bytes in the character codes. While accented Latin letters, and also Cyrillic or Greek letter, occupy one byte each in single-byte legacy character sets, such as WE8MSWIN1252 or CL8MSWIN1251, they occupy two bytes in UTF8 and AL32UTF8. Certain special characters, such as the Euro currency symbol, occupy three bytes. Therefore, any affected columns, PL/SQL variables and user-defined data type attributes on the database side whose lengths are expressed in bytes need to be adjusted to accommodate additional bytes that are added in the client/server character set conversion when data comes from the application to the database.</p>
<p>If an application does not rely on the database to control data lengths, controlling the length limits itself, and if all data processed by the application is entered into the database only through the application, byte lengths of affected columns, PL/SQL variables, and user-defined data types attributes may be adjusted by increasing them appropriately, usually by multiplying by three. If an application relies on the database to control data lengths, by handling the returned errors (such as ORA-12899), or if data for the application may come from external sources, the recommended way of adjusting lengths in SQL and PL/SQL is to keep the original absolute length number and to change the length semantics from bytes to characters. That is, a <code dir="ltr">VARCHAR2(10 [BYTE])</code> column or PL/SQL variable should become a <code dir="ltr">VARCHAR2(10 CHAR)</code> column or variable.</p>
<p>As the above length issues obviously affect the existing database contents as well, the column and attribute lengths usually have to be increased already as part of the cleansing step of the database character set migration process. The PL/SQL variables must be adjusted independently, unless their data type is expressed using the <code dir="ltr">%TYPE</code> attribute.</p>
<p>A significant problem exists because of absolute length limits of basic character data types. A <code dir="ltr">VARCHAR2</code> value stored in a database cannot exceed 4000 bytes and a <code dir="ltr">CHAR</code> value cannot exceed 200 types. Therefore, you can expand <code dir="ltr">VARCHAR2</code> columns and attributes only up to 1333 (in UTF8) or 1000 (in AL32UTF8) characters to have a guarantee that they can really store that number of random character codes without hitting the data type limit. If longer values are already commonly processed by an application, it may be impossible to continue running the application without modifying it, for example, to use the <code dir="ltr">CLOB</code> data type instead of <code dir="ltr">VARCHAR2</code>.</p>
<p>Independently of the above length issues, some applications may rely on a specific binary sorting order of queried character values coming from the database. Characters of the US7ASCII and WE8ISO8859P1 character sets keep the same order in UTF8 and AL32UTF8 but characters from other character sets do not. You may need to create custom linguistic definitions using the Oracle Local Builder utility to simulate the binary order of a legacy character set in an UTF8 or AL32UTF8 database. In general, Oracle recommends that you modify the application to not rely on a specific binary sort order instead of creating custom linguistic definitions, which increase complexity and cost of database administration and may impact query performance.</p>
<p>In addition to these changes, the database side of the application code might require further changes required by the new Unicode character encoding, as described in the next section.</p>
<div class="infoboxnotealso">
<p class="notep1">See Also:</p>
<a class="olink NLSPG294" href="../NLSPG/ch5lingsort.htm#NLSPG294"><span class="italic">Oracle Database Globalization Support Guide</span></a> for more information about creating custom linguistic definitions</div>
</div>
<!-- class="sect2" -->
<div id="DUMAG379" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref211"></a>
<h3 class="sect2">Changes to SQL and PL/SQL Code</h3>
<p>Because SQL an<a id="sthref212"></a><a id="sthref213"></a><a id="sthref214"></a><a id="sthref215"></a>d PL/SQL code runs inside the database, its processing character set, that is, the character set in which the processed data is encoded - in this case, the database character set - always changes after a database migration to Unicode. This is different from the client-side application code, which can retain its processing character set after migration if <code dir="ltr">NLS_LANG</code> setting is left unchanged.</p>
<p>Most PL/SQL statements, expressions, functions, and procedures work independently of the database character set and require no adaptation. However, there are still of number of functions that provide different results for different processing character sets. SQL and PL/SQL code containing the following functions must be reviewed and modified as required to account for the migration to Unicode:</p>
<ul>
<li>
<p>Functions depending on specific binary character codes: <code dir="ltr">CHR</code>, <code dir="ltr">ASCII</code>, and <code dir="ltr">DUMP</code></p>
</li>
<li>
<p>Functions depending on character code widths in bytes: <code dir="ltr">LENGTHB</code>, <code dir="ltr">VSIZE</code></p>
</li>
<li>
<p>Functions working with byte offsets: <code dir="ltr">INSTRB</code>, <code dir="ltr">SUBSTRB</code></p>
</li>
<li>
<p>Character set conversion functions: <code dir="ltr">CONVERT</code></p>
</li>
<li>
<p>String-to-binary casting: <code dir="ltr">UTL_RAW.CAST_TO_VARCHAR2</code>, <code dir="ltr">UTL_RAW.CAST_TO_RAW</code>, <code dir="ltr">UTL_I18N.STRING_TO_RAW</code>, <code dir="ltr">UTL_I18N.RAW_TO_CHAR</code></p>
</li>
</ul>
<p>Also, the standard package <code dir="ltr">UTL_FILE</code> allows character data to be stored in external files in the database character set. Consumers of those files may need to be adapted to deal with the new file encoding.</p>
<p>The SQL and PL/SQL expressions must be reviewed in view definitions, PL/SQL stored modules, user-defined data type methods, triggers, check constraints, but also event rule conditions (see <code dir="ltr">DBMS_RULE_ADM</code>), row-level security (RLS/VPD) policies (see <code dir="ltr">DBMS_RLS</code>), fine-grained auditing policies (see <code dir="ltr">DBMS_FGA</code>) and any other auxiliary database objects definitions that may reference SQL or PL/SQL expressions.</p>
<div class="infobox-note">
<p class="notep1">Caution:</p>
While uncommon, row-level security or fine-grained auditing policies may be defined using SQL expressions that are sensitive to character encoding. Ensure that you review all such policies to verify that protection of sensitive data is not compromised because of the database character set change.</div>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="BABFJEGB"></a>
<div id="DUMAG1521" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">Repairing Database Character Set Metadata</h2>
<p>If your database has been in what is commonly called a pass-through configuration, where the client cha<a id="sthref216"></a>racter set is defined (usually through the <code dir="ltr">NLS_LANG</code> client setting) to be equal to the database character set, the character data in your database could be stored in a different character set from the declared database character set. In this scenario, the recommended solution is to migrate your database to Unicode by using the DMU assumed database character set feature to indicate the actual character set for the data. In case migrating to Unicode is not immediately feasible due to business or technical constraints, it would be desirable to at least correct the database character set declaration to match with the database contents.</p>
<p>With Database Migration Assistant for Unicode, release 1.2, you can repair the database character set metadata in such cases using the <code dir="ltr">CSREPAIR</code> script. The <code dir="ltr">CSREPAIR</code> script works in conjunction with the DMU client and accesses the DMU repository. It can be used to change the database character set declaration to the real character set of the data only after the DMU has performed a full database scan by setting the Assumed Database Character Set property to the target character set and no invalid representation issues have been reported, which verifies that all existing data in the database is defined according to the assumed database character set. Note that <code dir="ltr">CSREPAIR</code> only changes the database character set declaration in the data dictionary metadata and does not convert any database data.</p>
<p>You can find the <code dir="ltr">CSREPAIR</code> script under the <code dir="ltr">admin</code> subdirectory of the DMU installation. The requirements when using the <code dir="ltr">CSREPAIR</code> script are:</p>
<ol>
<li>
<p>You must first perform a successful full database scan in the DMU with the Assumed Database Character Set property set to the real character set of the data. In this case, the assumed database character set must be different from the current database character set or else nothing will be done. The <code dir="ltr">CSREPAIR</code> script will not proceed if the DMU reports the existence of data with invalid binary representation. It will, however, proceed if data that is changeless, convertible or exceeding length limits is reported in the scan results.</p>
</li>
<li>
<p>The target character set in the assumed database character set must be a binary superset of US7ASCII.</p>
</li>
<li>
<p>Only repairing from single-byte to single-byte character sets or multi-byte to multi-byte character sets is allowed as no conversion of <code dir="ltr">CLOB</code> data will be attempted.</p>
</li>
<li>
<p>If you set the assumed character set at the column level, then the value must be the same as the assumed database character set. Otherwise, <code dir="ltr">CSREPAIR</code> will not run.</p>
</li>
<li>
<p>You must have the <code dir="ltr">SYSDBA</code> privilege to run <code dir="ltr">CSREPAIR</code>. To run <code dir="ltr">CSREPAIR</code> on a pluggable database (PDB) in Oracle Database 12<span class="italic">c</span>, you must be either the <code dir="ltr">SYS</code> user or a common user with the <code dir="ltr">SYSDBA</code> privilege in both the local PDB and the CDB.</p>
</li>
</ol>
<div id="DUMAG1522" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref217"></a>
<h3 class="sect2">Example: Using CSREPAIR</h3>
<p>A typical example is storing WE8MSWIN1252 data in a WE8ISO8859P1 database via the pass-through configuration. To correct the database character set from WE8ISO8859P1 to WE8MSWIN1252, perform the following steps:</p>
<ol>
<li>
<p>Set up the DMU and connect to the target WE8ISO8859P1 database.</p>
</li>
<li>
<p>Open the Database Properties tab in the DMU.</p>
</li>
<li>
<p>Set the Assumed Database Character Set property to WE8MSWIN1252.</p>
</li>
<li>
<p>Use the DMU to perform a full database scan.</p>
</li>
<li>
<p>Open the Database Scan Report and verify there is no data reported under the Invalid Representation category.</p>
</li>
<li>
<p>Exit from the DMU client.</p>
</li>
<li>
<p>Start the SQL*Plus utility and connect as a user with the <code dir="ltr">SYSDBA</code> privilege.</p>
</li>
<li>
<p>Run the <code dir="ltr">CSREPAIR</code> script:</p>
<p><code dir="ltr">SQL&gt; @@CSREPAIR.PLB</code></p>
<p>Upon completion, you should get the message:</p>
<p>The database character set has been successfully changed to WE8MSWIN1252. You must restart the database now.</p>
</li>
<li>
<p>Shut down and restart the database.</p>
</li>
</ol>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" -->
<a id="BABJDDGJ"></a>
<div id="DUMAG1523" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">Updating the DMU Version</h2>
<p>You can chec<a id="sthref218"></a><a id="sthref219"></a>k for and install the latest version of the DMU by using the DMU live update feature. It enables you to find out if a new version of the DMU is available from the DMU update center. If you decide to upgrade to the new version, the live update feature can download the software package and upgrade the existing installation for you automatically.</p>
<p>The DMU can detect new version availability at startup. If a new version is found, a message will be shown at the lower-right corner of the main window.</p>
<p class="subhead2"><a id="DUMAG1524"></a>To check for updates to the DMU version:</p>
<ol>
<li>
<p>To start the live update feature, click on the message at the bottom of the main window or choose <span class="bold">Check</span> <span class="bold">for</span> <span class="bold">Updates</span> under the <span class="bold">Help</span> menu.</p>
<div id="DUMAG1525" class="figure">
<p class="titleinfigure"><a id="sthref220"></a>Figure 5-1 Check for Updates Wizard - Welcome</p>
<img width="641" height="478" src="img/updatewiz.gif" alt="Description of Figure 5-1 follows"/><br/>
<a id="sthref221" href="img_text/updatewiz.htm">Description of &#34;Figure 5-1 Check for Updates Wizard - Welcome&#34;</a><br/>
<br/></div>
<!-- class="figure" -->
<p>The <span class="bold">Check</span> <span class="bold">For</span> <span class="bold">Updates</span> wizard appears. The wizard checks for the availability of DMU updates from the DMU update center and helps you download and install the updates automatically.</p>
</li>
<li>
<p>Click <span class="bold">Next</span>. The wizard displays the available DMU updates. If there is no newer version available than the currently installed version, then the message will indicate your DMU version is up-to-date.</p>
<div id="DUMAG1526" class="figure">
<p class="titleinfigure"><a id="sthref222"></a>Figure 5-2 Check for Updates Wizard - Available Versions</p>
<img width="641" height="480" src="img/checkupdb.gif" alt="Description of Figure 5-2 follows"/><br/>
<a id="sthref223" href="img_text/checkupdb.htm">Description of &#34;Figure 5-2 Check for Updates Wizard - Available Versions&#34;</a><br/>
<br/></div>
<!-- class="figure" --></li>
<li>
<p>Click <span class="bold">Next</span>. The Wizard begins to download the new DMU package from the update center. Wait for the download to complete.</p>
<div id="DUMAG1527" class="figure">
<p class="titleinfigure"><a id="sthref224"></a>Figure 5-3 Check for Updates Wizard - Downloading New DMU Version</p>
<img width="639" height="478" src="img/updatewizc.gif" alt="Description of Figure 5-3 follows"/><br/>
<a id="sthref225" href="img_text/updatewizc.htm">Description of &#34;Figure 5-3 Check for Updates Wizard - Downloading New DMU Version&#34;</a><br/>
<br/></div>
<!-- class="figure" --></li>
<li>
<p>Click <span class="bold">Next</span>. The Summary page is displayed. On this page, you have the option of either exiting the DMU and installing the new version immediately or completing the installation later. If you choose <span class="bold">Yes</span>, the DMU will exit and start the installation process in the background. After the installation is complete, the DMU restarts in the new version.</p>
<div id="DUMAG1528" class="figure">
<p class="titleinfigure"><a id="sthref226"></a>Figure 5-4 Check for Updates Wizard - Summary</p>
<img width="640" height="479" src="img/updatewizd.gif" alt="Description of Figure 5-4 follows"/><br/>
<a id="sthref227" href="img_text/updatewizd.htm">Description of &#34;Figure 5-4 Check for Updates Wizard - Summary&#34;</a><br/>
<br/></div>
<!-- class="figure" -->
<p>Note that upgrading to a new DMU version may require the migration repository to be re-installed. As a result, the previous scan results and scheduled cleansing actions will not be preserved after the upgrade.</p>
</li>
<li>
<p>If you are behind a firewall or use a proxy to access web pages, you may need to configure your proxy settings on the Auto Update page of the Preferences dialog box before you can connect to the DMU update center.</p>
<p>To configure your proxy settings, choose <span class="bold">Preferences</span> under the <span class="bold">Tools</span> menu. The Preferences dialog appears.</p>
<div id="DUMAG1529" class="figure">
<p class="titleinfigure"><a id="sthref228"></a>Figure 5-5 Preferences: Auto Update</p>
<img width="700" height="498" src="img/prefsauto.gif" alt="Description of Figure 5-5 follows"/><br/>
<a id="sthref229" href="img_text/prefsauto.htm">Description of &#34;Figure 5-5 Preferences: Auto Update&#34;</a><br/>
<br/></div>
<!-- class="figure" --></li>
</ol>
<p>If you select <span class="bold">Use</span> <span class="bold">HTTP</span> <span class="bold">Proxy</span> <span class="bold">Server</span>, enter the values into the Host Name and Port Number fields.</p>
<p>If you select <span class="bold">Proxy</span> <span class="bold">Server</span> <span class="bold">Requires</span> <span class="bold">Authentication</span>, enter the values into the User Name and Password fields.</p>
<p>If you select <span class="bold">Automatically</span> <span class="bold">Check</span> <span class="bold">for</span> <span class="bold">Updates</span>, the DMU checks to see if there is a new DMU version during startup.</p>
<p>Click <span class="bold">OK</span> to close the Preferences dialog and finish setting the proxy server.</p>
</div>
<!-- class="sect1" -->
<a id="BABGHDHJ"></a>
<div id="DUMAG1530" class="sect1"><!-- infolevel="all" infotype="General" -->
<h2 class="sect1">DMU Accessibility Information</h2>
<p>It is our goal to make Oracle Products, Services, and supporting documentation accessible to the disabled community. Oracle Database Migration Assistant for Unicode supports accessibility features.</p>
<p>For additional accessibility information for Oracle products, see the Oracle Accessibility Program page at: <code dir="ltr"><a href="http://www.oracle.com/accessibility/">http://www.oracle.com/accessibility/</a></code>.</p>
<div id="DUMAG1531" class="sect2"><!-- infolevel="all" infotype="General" --><a id="sthref230"></a>
<h3 class="sect2">Using a Screen Reader and Java Access Bridge with the DMU</h3>
<p>In order for assistive technologies, like screen readers, to work with Java-based applications and applets, the Windows-based computer must also have Sun&#39;s Java Access Bridge installed.</p>
<p>To make the best use of our accessibility features, Oracle Corporation recommends the following minimum configuration:</p>
<ul>
<li>
<p>Windows XP, Windows Vista</p>
</li>
<li>
<p>Java J2SE 1.6.0_24</p>
</li>
<li>
<p>Java Access Bridge 2.0.1</p>
</li>
<li>
<p>JAWS 12.0.522</p>
</li>
<li>
<p>Microsoft Internet Explorer 7.0 or later</p>
</li>
<li>
<p>Mozilla Firefox 3.5 or later</p>
</li>
</ul>
<p>Please refer to the following procedures to set up a screen reader and Java Access Bridge.</p>
<ol>
<li>
<p>Install the screen reader, if it is not already installed.</p>
<p>Refer to the documentation for your screen reader for more information about installation.</p>
</li>
<li>
<p>Install the DMU.</p>
</li>
<li>
<p>Download Java Access Bridge for Windows version 2.0.1. The file you will download is <code dir="ltr">accessbridge-2_0_1.zip</code>. It is available from:</p>
<p><code dir="ltr"><a href="http://www.oracle.com/technetwork/java/javase/tech/index-jsp-136191.html">http://www.oracle.com/technetwork/java/javase/tech/index-jsp-136191.html</a></code></p>
<p>Refer to the Java Access Bridge documentation available from this web site for more information about installation and the Java Access Bridge.</p>
</li>
<li>
<p>Extract (unzip) the contents to a folder, for example, <code dir="ltr">accessbridge_home</code>.</p>
</li>
<li>
<p>Install Java Access Bridge by running <code dir="ltr">Install.exe</code> from the <code dir="ltr">&lt;accessbridge_home&gt;\installer</code> folder.</p>
<p>The installer first checks the JDK version for compatibility, then the Available Java virtual machines dialog displays.</p>
</li>
<li>
<p>Click <span class="bold">Search</span> <span class="bold">Disks</span>. Then select to search only the drive that contains the JDK version in the program files directory (if it exists).</p>
<p>The search process can take a long time on a large disk with many instances of JDK, or when searching multiple disks. However, unless you complete an exhaustive search of your disk, Access Bridge will not be optimally configured, and will not be correctly installed to all of the Java VMs on your system. After selecting the disk to search, click <span class="bold">Search</span>.</p>
</li>
<li>
<p>Confirm that you want to install the Java Access Bridge into each of the Java virtual machines displayed in the dialog, by clicking <span class="bold">Install</span> <span class="bold">in</span> <span class="bold">All</span>.</p>
</li>
<li>
<p>Click <span class="bold">OK</span> when you see the Installation Completed message.</p>
</li>
<li>
<p>Confirm that the following files have been installed in the <code dir="ltr">Winnt\System32</code> directory (o the equivalent Windows XP or Vista directory), or copy them from <code dir="ltr">&lt;accessbridge_home&gt;\installerfiles</code> as they must be in the system path in order to work with the DMU:</p>
<ul>
<li>
<p><code dir="ltr">JavaAccessBridge.dll</code></p>
</li>
<li>
<p><code dir="ltr">JAWTAccessBridge.dll</code></p>
</li>
<li>
<p><code dir="ltr">WindowsAccessBridge.dll</code></p>
</li>
</ul>
<p>Note that the system directory is required in the <code dir="ltr">PATH</code> system variable.</p>
</li>
<li>
<p>Confirm that the following files have been installed in the <code dir="ltr">jdk\jre\lib\ext</code> directory, or copy them from <code dir="ltr">&lt;accessbridge_home&gt;\installerfiles</code>:</p>
<ul>
<li>
<p><code dir="ltr">access-bridget.jar</code></p>
</li>
<li>
<p><code dir="ltr">jaccess-1_4.jar</code></p>
</li>
</ul>
</li>
<li>
<p>Confirm that the file <code dir="ltr">accessibility.properties</code> has been installed in the <code dir="ltr">jdk\jre\lib</code> directory, or copy it from <code dir="ltr">\installerfiles</code>.</p>
</li>
<li>
<p>Start your screen reader.</p>
</li>
<li>
<p>Start the DMU.</p>
</li>
</ol>
<p>The steps above assume you are running Windows and using a Windows-based screen reader. A console window that contains error information (if any) will open first and then the main DMU window will appear, once the DMU has started. Any messages that appear will not affect the DMU functionality.</p>
</div>
<!-- class="sect2" --></div>
<!-- class="sect1" --></div>
<!-- class="chapter" --></div>
<!-- class="ind" -->
<!-- Start Footer -->
</div>
<!-- add extra wrapper close div-->
<footer><!--
<hr />
<table class="cellalignment3209">
<tr>
<td class="cellalignment3216">
<table class="cellalignment3214">
<tr>
<td class="cellalignment3213"><a href="ch4scenarios.htm"><img width="24" height="24" src="../dcommon/gifs/leftnav.gif" alt="Go to previous page" /><br />
<span class="icon">Previous</span></a></td>
<td class="cellalignment3213"><a href="ch6cleansing.htm"><img width="24" height="24" src="../dcommon/gifs/rightnav.gif" alt="Go to next page" /><br />
<span class="icon">Next</span></a></td>
</tr>
</table>
</td>
<td class="cellalignment-copyrightlogo"><img width="144" height="18" src="../dcommon/gifs/oracle.gif" alt="Oracle" /><br />
Copyright&nbsp;&copy;&nbsp;2011, 2015,&nbsp;Oracle&nbsp;and/or&nbsp;its&nbsp;affiliates.&nbsp;All&nbsp;rights&nbsp;reserved.<br />
<a href="../dcommon/html/cpyr.htm">Legal Notices</a></td>
<td class="cellalignment3218">
<table class="cellalignment3212">
<tr>
<td class="cellalignment3213"><a href="../index.htm"><img width="24" height="24" src="../dcommon/gifs/doclib.gif" alt="Go to Documentation Home" /><br />
<span class="icon">Home</span></a></td>
<td class="cellalignment3213"><a href="../nav/portal_booklist.htm"><img width="24" height="24" src="../dcommon/gifs/booklist.gif" alt="Go to Book List" /><br />
<span class="icon">Book List</span></a></td>
<td class="cellalignment3213"><a href="toc.htm"><img width="24" height="24" src="../dcommon/gifs/toc.gif" alt="Go to Table of Contents" /><br />
<span class="icon">Contents</span></a></td>
<td class="cellalignment3213"><a href="index.htm"><img width="24" height="24" src="../dcommon/gifs/index.gif" alt="Go to Index" /><br />
<span class="icon">Index</span></a></td>
<td class="cellalignment3213"><a href="../nav/mindx.htm"><img width="24" height="24" src="../dcommon/gifs/masterix.gif" alt="Go to Master Index" /><br />
<span class="icon">Master Index</span></a></td>
<td class="cellalignment3213"><a href="../dcommon/html/feedback.htm"><img width="24" height="24" src="../dcommon/gifs/feedbck2.gif" alt="Go to Feedback page" /><br />
<span class="icon">Contact Us</span></a></td>
</tr>
</table>
</td>
</tr>
</table>
--></footer>
<noscript>
<p>Scripting on this page enhances content navigation, but does not change the content in any way.</p>
</noscript>


</body></html>